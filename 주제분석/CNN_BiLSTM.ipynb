{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D ,MaxPooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"FINAL_RE_PLC_review_tokenized_okt_30377.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review_tokens'] = data['review_tokens'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['review_tokens'])\n",
    "X = tokenizer.texts_to_sequences(data['review_tokens']) # Sequence 변환\n",
    "max_len = 82\n",
    "X = pad_sequences(X, max_len)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(data.plc)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.load('embedding_mat.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM + CNN 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, GRU, Concatenate, Dropout, SpatialDropout1D\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import optimizers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
    "model.add(SpatialDropout1D(rate = 0.2))\n",
    "model.add(Conv1D(filters = 64, kernel_size = 5, padding = 'same', activation = 'relu', strides = 1)) # padding = 'valid'\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dense(units = 300, activation='relu'))\n",
    "model.add(Dropout(rate = 0.2))  \n",
    "model.add(Dense(349, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[tfa.metrics.FBetaScore(num_classes=349, average='micro', beta=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
    "val_f1_score = float('-inf')\n",
    "model_checkpoint = ModelCheckpoint('CNN_BiLSTM.h5', monitor = 'fbeta_score', mode = 'max', verbose = 1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "238/238 [==============================] - 69s 226ms/step - loss: 4.9101 - fbeta_score: 0.0562\n",
      "\n",
      "Epoch 00001: fbeta_score improved from -inf to 0.06130, saving model to CNN_BiLSTM.h5\n",
      "Epoch 2/150\n",
      "238/238 [==============================] - 54s 227ms/step - loss: 4.4402 - fbeta_score: 0.1067\n",
      "\n",
      "Epoch 00002: fbeta_score improved from 0.06130 to 0.12572, saving model to CNN_BiLSTM.h5\n",
      "Epoch 3/150\n",
      "238/238 [==============================] - 53s 221ms/step - loss: 3.9377 - fbeta_score: 0.1753\n",
      "\n",
      "Epoch 00003: fbeta_score improved from 0.12572 to 0.19265, saving model to CNN_BiLSTM.h5\n",
      "Epoch 4/150\n",
      "238/238 [==============================] - 53s 224ms/step - loss: 3.6231 - fbeta_score: 0.2269\n",
      "\n",
      "Epoch 00004: fbeta_score improved from 0.19265 to 0.23399, saving model to CNN_BiLSTM.h5\n",
      "Epoch 5/150\n",
      "238/238 [==============================] - 53s 223ms/step - loss: 3.4049 - fbeta_score: 0.2607\n",
      "\n",
      "Epoch 00005: fbeta_score improved from 0.23399 to 0.26635, saving model to CNN_BiLSTM.h5\n",
      "Epoch 6/150\n",
      "238/238 [==============================] - 44s 185ms/step - loss: 3.2616 - fbeta_score: 0.2850\n",
      "\n",
      "Epoch 00006: fbeta_score improved from 0.26635 to 0.28752, saving model to CNN_BiLSTM.h5\n",
      "Epoch 7/150\n",
      "238/238 [==============================] - 41s 173ms/step - loss: 3.1008 - fbeta_score: 0.3100\n",
      "\n",
      "Epoch 00007: fbeta_score improved from 0.28752 to 0.30984, saving model to CNN_BiLSTM.h5\n",
      "Epoch 8/150\n",
      "238/238 [==============================] - 46s 192ms/step - loss: 3.0114 - fbeta_score: 0.3224\n",
      "\n",
      "Epoch 00008: fbeta_score improved from 0.30984 to 0.32623, saving model to CNN_BiLSTM.h5\n",
      "Epoch 9/150\n",
      "238/238 [==============================] - 50s 208ms/step - loss: 2.9042 - fbeta_score: 0.3424\n",
      "\n",
      "Epoch 00009: fbeta_score improved from 0.32623 to 0.34236, saving model to CNN_BiLSTM.h5\n",
      "Epoch 10/150\n",
      "238/238 [==============================] - 50s 210ms/step - loss: 2.8112 - fbeta_score: 0.3557\n",
      "\n",
      "Epoch 00010: fbeta_score improved from 0.34236 to 0.35688, saving model to CNN_BiLSTM.h5\n",
      "Epoch 11/150\n",
      "238/238 [==============================] - 50s 211ms/step - loss: 2.7560 - fbeta_score: 0.3668\n",
      "\n",
      "Epoch 00011: fbeta_score improved from 0.35688 to 0.36847, saving model to CNN_BiLSTM.h5\n",
      "Epoch 12/150\n",
      "238/238 [==============================] - 50s 212ms/step - loss: 2.6537 - fbeta_score: 0.3829\n",
      "\n",
      "Epoch 00012: fbeta_score improved from 0.36847 to 0.37963, saving model to CNN_BiLSTM.h5\n",
      "Epoch 13/150\n",
      "238/238 [==============================] - 50s 211ms/step - loss: 2.5870 - fbeta_score: 0.3874\n",
      "\n",
      "Epoch 00013: fbeta_score improved from 0.37963 to 0.38444, saving model to CNN_BiLSTM.h5\n",
      "Epoch 14/150\n",
      "238/238 [==============================] - 51s 212ms/step - loss: 2.5130 - fbeta_score: 0.4055\n",
      "\n",
      "Epoch 00014: fbeta_score improved from 0.38444 to 0.40076, saving model to CNN_BiLSTM.h5\n",
      "Epoch 15/150\n",
      "238/238 [==============================] - 50s 208ms/step - loss: 2.4770 - fbeta_score: 0.4092\n",
      "\n",
      "Epoch 00015: fbeta_score improved from 0.40076 to 0.40692, saving model to CNN_BiLSTM.h5\n",
      "Epoch 16/150\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 2.4026 - fbeta_score: 0.4208\n",
      "\n",
      "Epoch 00016: fbeta_score improved from 0.40692 to 0.41459, saving model to CNN_BiLSTM.h5\n",
      "Epoch 17/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 2.3564 - fbeta_score: 0.4242\n",
      "\n",
      "Epoch 00017: fbeta_score improved from 0.41459 to 0.42091, saving model to CNN_BiLSTM.h5\n",
      "Epoch 18/150\n",
      "238/238 [==============================] - 54s 229ms/step - loss: 2.3057 - fbeta_score: 0.4361\n",
      "\n",
      "Epoch 00018: fbeta_score improved from 0.42091 to 0.43187, saving model to CNN_BiLSTM.h5\n",
      "Epoch 19/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 2.2507 - fbeta_score: 0.4478\n",
      "\n",
      "Epoch 00019: fbeta_score improved from 0.43187 to 0.43895, saving model to CNN_BiLSTM.h5\n",
      "Epoch 20/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 2.2400 - fbeta_score: 0.4496\n",
      "\n",
      "Epoch 00020: fbeta_score improved from 0.43895 to 0.44751, saving model to CNN_BiLSTM.h5\n",
      "Epoch 21/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 2.1677 - fbeta_score: 0.4600\n",
      "\n",
      "Epoch 00021: fbeta_score improved from 0.44751 to 0.45505, saving model to CNN_BiLSTM.h5\n",
      "Epoch 22/150\n",
      "238/238 [==============================] - 54s 229ms/step - loss: 2.1362 - fbeta_score: 0.4626\n",
      "\n",
      "Epoch 00022: fbeta_score improved from 0.45505 to 0.45778, saving model to CNN_BiLSTM.h5\n",
      "Epoch 23/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 2.0890 - fbeta_score: 0.4727\n",
      "\n",
      "Epoch 00023: fbeta_score improved from 0.45778 to 0.46463, saving model to CNN_BiLSTM.h5\n",
      "Epoch 24/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 2.0743 - fbeta_score: 0.4756\n",
      "\n",
      "Epoch 00024: fbeta_score improved from 0.46463 to 0.46897, saving model to CNN_BiLSTM.h5\n",
      "Epoch 25/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 2.0416 - fbeta_score: 0.4748\n",
      "\n",
      "Epoch 00025: fbeta_score improved from 0.46897 to 0.47592, saving model to CNN_BiLSTM.h5\n",
      "Epoch 26/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.9802 - fbeta_score: 0.4942\n",
      "\n",
      "Epoch 00026: fbeta_score improved from 0.47592 to 0.48527, saving model to CNN_BiLSTM.h5\n",
      "Epoch 27/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.9470 - fbeta_score: 0.4973\n",
      "\n",
      "Epoch 00027: fbeta_score improved from 0.48527 to 0.48889, saving model to CNN_BiLSTM.h5\n",
      "Epoch 28/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.9160 - fbeta_score: 0.5005\n",
      "\n",
      "Epoch 00028: fbeta_score improved from 0.48889 to 0.49287, saving model to CNN_BiLSTM.h5\n",
      "Epoch 29/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.8938 - fbeta_score: 0.5039\n",
      "\n",
      "Epoch 00029: fbeta_score improved from 0.49287 to 0.50071, saving model to CNN_BiLSTM.h5\n",
      "Epoch 30/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.8545 - fbeta_score: 0.5073\n",
      "\n",
      "Epoch 00030: fbeta_score improved from 0.50071 to 0.50360, saving model to CNN_BiLSTM.h5\n",
      "Epoch 31/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.8403 - fbeta_score: 0.5139\n",
      "\n",
      "Epoch 00031: fbeta_score improved from 0.50360 to 0.50647, saving model to CNN_BiLSTM.h5\n",
      "Epoch 32/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.8112 - fbeta_score: 0.5193\n",
      "\n",
      "Epoch 00032: fbeta_score improved from 0.50647 to 0.51463, saving model to CNN_BiLSTM.h5\n",
      "Epoch 33/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.7664 - fbeta_score: 0.5285\n",
      "\n",
      "Epoch 00033: fbeta_score improved from 0.51463 to 0.52082, saving model to CNN_BiLSTM.h5\n",
      "Epoch 34/150\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 1.7504 - fbeta_score: 0.5293\n",
      "\n",
      "Epoch 00034: fbeta_score improved from 0.52082 to 0.52599, saving model to CNN_BiLSTM.h5\n",
      "Epoch 35/150\n",
      "238/238 [==============================] - 54s 226ms/step - loss: 1.7180 - fbeta_score: 0.5362\n",
      "\n",
      "Epoch 00035: fbeta_score improved from 0.52599 to 0.52991, saving model to CNN_BiLSTM.h5\n",
      "Epoch 36/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.6978 - fbeta_score: 0.5399\n",
      "\n",
      "Epoch 00036: fbeta_score improved from 0.52991 to 0.53356, saving model to CNN_BiLSTM.h5\n",
      "Epoch 37/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.6654 - fbeta_score: 0.5451\n",
      "\n",
      "Epoch 00037: fbeta_score improved from 0.53356 to 0.53748, saving model to CNN_BiLSTM.h5\n",
      "Epoch 38/150\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 1.6261 - fbeta_score: 0.5545\n",
      "\n",
      "Epoch 00038: fbeta_score improved from 0.53748 to 0.54630, saving model to CNN_BiLSTM.h5\n",
      "Epoch 39/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.6238 - fbeta_score: 0.5571\n",
      "\n",
      "Epoch 00039: fbeta_score improved from 0.54630 to 0.54874, saving model to CNN_BiLSTM.h5\n",
      "Epoch 40/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.6033 - fbeta_score: 0.5617\n",
      "\n",
      "Epoch 00040: fbeta_score improved from 0.54874 to 0.55486, saving model to CNN_BiLSTM.h5\n",
      "Epoch 41/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 1.5706 - fbeta_score: 0.5674\n",
      "\n",
      "Epoch 00041: fbeta_score improved from 0.55486 to 0.55884, saving model to CNN_BiLSTM.h5\n",
      "Epoch 42/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 55s 230ms/step - loss: 1.5340 - fbeta_score: 0.5710\n",
      "\n",
      "Epoch 00042: fbeta_score improved from 0.55884 to 0.56131, saving model to CNN_BiLSTM.h5\n",
      "Epoch 43/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.5329 - fbeta_score: 0.5706\n",
      "\n",
      "Epoch 00043: fbeta_score improved from 0.56131 to 0.56539, saving model to CNN_BiLSTM.h5\n",
      "Epoch 44/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.5082 - fbeta_score: 0.5779\n",
      "\n",
      "Epoch 00044: fbeta_score improved from 0.56539 to 0.57096, saving model to CNN_BiLSTM.h5\n",
      "Epoch 45/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.4841 - fbeta_score: 0.5839\n",
      "\n",
      "Epoch 00045: fbeta_score improved from 0.57096 to 0.57346, saving model to CNN_BiLSTM.h5\n",
      "Epoch 46/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.4732 - fbeta_score: 0.5845\n",
      "\n",
      "Epoch 00046: fbeta_score improved from 0.57346 to 0.57728, saving model to CNN_BiLSTM.h5\n",
      "Epoch 47/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.4468 - fbeta_score: 0.5861\n",
      "\n",
      "Epoch 00047: fbeta_score improved from 0.57728 to 0.57945, saving model to CNN_BiLSTM.h5\n",
      "Epoch 48/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.4306 - fbeta_score: 0.5941\n",
      "\n",
      "Epoch 00048: fbeta_score improved from 0.57945 to 0.58498, saving model to CNN_BiLSTM.h5\n",
      "Epoch 49/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.4247 - fbeta_score: 0.5905\n",
      "\n",
      "Epoch 00049: fbeta_score did not improve from 0.58498\n",
      "Epoch 50/150\n",
      "238/238 [==============================] - 54s 229ms/step - loss: 1.3807 - fbeta_score: 0.6041\n",
      "\n",
      "Epoch 00050: fbeta_score improved from 0.58498 to 0.59315, saving model to CNN_BiLSTM.h5\n",
      "Epoch 51/150\n",
      "238/238 [==============================] - 54s 227ms/step - loss: 1.4023 - fbeta_score: 0.5972\n",
      "\n",
      "Epoch 00051: fbeta_score did not improve from 0.59315\n",
      "Epoch 52/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.3802 - fbeta_score: 0.6044\n",
      "\n",
      "Epoch 00052: fbeta_score improved from 0.59315 to 0.59858, saving model to CNN_BiLSTM.h5\n",
      "Epoch 53/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.3641 - fbeta_score: 0.6066\n",
      "\n",
      "Epoch 00053: fbeta_score improved from 0.59858 to 0.59996, saving model to CNN_BiLSTM.h5\n",
      "Epoch 54/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.3296 - fbeta_score: 0.6104\n",
      "\n",
      "Epoch 00054: fbeta_score improved from 0.59996 to 0.60282, saving model to CNN_BiLSTM.h5\n",
      "Epoch 55/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.3333 - fbeta_score: 0.6143\n",
      "\n",
      "Epoch 00055: fbeta_score improved from 0.60282 to 0.60783, saving model to CNN_BiLSTM.h5\n",
      "Epoch 56/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.2996 - fbeta_score: 0.6215\n",
      "\n",
      "Epoch 00056: fbeta_score improved from 0.60783 to 0.60934, saving model to CNN_BiLSTM.h5\n",
      "Epoch 57/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.3004 - fbeta_score: 0.6208\n",
      "\n",
      "Epoch 00057: fbeta_score improved from 0.60934 to 0.61398, saving model to CNN_BiLSTM.h5\n",
      "Epoch 58/150\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 1.2832 - fbeta_score: 0.6234\n",
      "\n",
      "Epoch 00058: fbeta_score improved from 0.61398 to 0.61665, saving model to CNN_BiLSTM.h5\n",
      "Epoch 59/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.2733 - fbeta_score: 0.6279\n",
      "\n",
      "Epoch 00059: fbeta_score improved from 0.61665 to 0.61738, saving model to CNN_BiLSTM.h5\n",
      "Epoch 60/150\n",
      "238/238 [==============================] - 54s 229ms/step - loss: 1.2645 - fbeta_score: 0.6305\n",
      "\n",
      "Epoch 00060: fbeta_score improved from 0.61738 to 0.62215, saving model to CNN_BiLSTM.h5\n",
      "Epoch 61/150\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 1.2535 - fbeta_score: 0.6336\n",
      "\n",
      "Epoch 00061: fbeta_score improved from 0.62215 to 0.62686, saving model to CNN_BiLSTM.h5\n",
      "Epoch 62/150\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 1.2121 - fbeta_score: 0.6433\n",
      "\n",
      "Epoch 00062: fbeta_score improved from 0.62686 to 0.63170, saving model to CNN_BiLSTM.h5\n",
      "Epoch 63/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.2138 - fbeta_score: 0.6396\n",
      "\n",
      "Epoch 00063: fbeta_score did not improve from 0.63170\n",
      "Epoch 64/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.2088 - fbeta_score: 0.6409\n",
      "\n",
      "Epoch 00064: fbeta_score improved from 0.63170 to 0.63413, saving model to CNN_BiLSTM.h5\n",
      "Epoch 65/150\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 1.1918 - fbeta_score: 0.6465\n",
      "\n",
      "Epoch 00065: fbeta_score improved from 0.63413 to 0.63762, saving model to CNN_BiLSTM.h5\n",
      "Epoch 66/150\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 1.1803 - fbeta_score: 0.6488\n",
      "\n",
      "Epoch 00066: fbeta_score improved from 0.63762 to 0.63890, saving model to CNN_BiLSTM.h5\n",
      "Epoch 67/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.1695 - fbeta_score: 0.6515\n",
      "\n",
      "Epoch 00067: fbeta_score improved from 0.63890 to 0.64246, saving model to CNN_BiLSTM.h5\n",
      "Epoch 68/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.1829 - fbeta_score: 0.6472\n",
      "\n",
      "Epoch 00068: fbeta_score did not improve from 0.64246\n",
      "Epoch 69/150\n",
      "238/238 [==============================] - 54s 229ms/step - loss: 1.1635 - fbeta_score: 0.6508\n",
      "\n",
      "Epoch 00069: fbeta_score improved from 0.64246 to 0.64490, saving model to CNN_BiLSTM.h5\n",
      "Epoch 70/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.1347 - fbeta_score: 0.6590\n",
      "\n",
      "Epoch 00070: fbeta_score improved from 0.64490 to 0.64809, saving model to CNN_BiLSTM.h5\n",
      "Epoch 71/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.1334 - fbeta_score: 0.6612\n",
      "\n",
      "Epoch 00071: fbeta_score improved from 0.64809 to 0.64937, saving model to CNN_BiLSTM.h5\n",
      "Epoch 72/150\n",
      "238/238 [==============================] - 54s 227ms/step - loss: 1.1409 - fbeta_score: 0.6563\n",
      "\n",
      "Epoch 00072: fbeta_score improved from 0.64937 to 0.65122, saving model to CNN_BiLSTM.h5\n",
      "Epoch 73/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.1108 - fbeta_score: 0.6656\n",
      "\n",
      "Epoch 00073: fbeta_score improved from 0.65122 to 0.65464, saving model to CNN_BiLSTM.h5\n",
      "Epoch 74/150\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 1.1204 - fbeta_score: 0.6596\n",
      "\n",
      "Epoch 00074: fbeta_score did not improve from 0.65464\n",
      "Epoch 75/150\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 1.1007 - fbeta_score: 0.6666\n",
      "\n",
      "Epoch 00075: fbeta_score improved from 0.65464 to 0.65994, saving model to CNN_BiLSTM.h5\n",
      "Epoch 76/150\n",
      "238/238 [==============================] - 54s 229ms/step - loss: 1.0879 - fbeta_score: 0.6734\n",
      "\n",
      "Epoch 00076: fbeta_score improved from 0.65994 to 0.66070, saving model to CNN_BiLSTM.h5\n",
      "Epoch 77/150\n",
      "238/238 [==============================] - 54s 225ms/step - loss: 1.1096 - fbeta_score: 0.6649\n",
      "\n",
      "Epoch 00077: fbeta_score did not improve from 0.66070\n",
      "Epoch 78/150\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 1.0817 - fbeta_score: 0.6715\n",
      "\n",
      "Epoch 00078: fbeta_score improved from 0.66070 to 0.66241, saving model to CNN_BiLSTM.h5\n",
      "Epoch 79/150\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 1.0579 - fbeta_score: 0.6780\n",
      "\n",
      "Epoch 00079: fbeta_score improved from 0.66241 to 0.66455, saving model to CNN_BiLSTM.h5\n",
      "Epoch 80/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.0742 - fbeta_score: 0.6731\n",
      "\n",
      "Epoch 00080: fbeta_score improved from 0.66455 to 0.66547, saving model to CNN_BiLSTM.h5\n",
      "Epoch 81/150\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 1.0599 - fbeta_score: 0.6743\n",
      "\n",
      "Epoch 00081: fbeta_score improved from 0.66547 to 0.66893, saving model to CNN_BiLSTM.h5\n",
      "Epoch 82/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.0429 - fbeta_score: 0.6843\n",
      "\n",
      "Epoch 00082: fbeta_score improved from 0.66893 to 0.67531, saving model to CNN_BiLSTM.h5\n",
      "Epoch 83/150\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 1.0500 - fbeta_score: 0.6796\n",
      "\n",
      "Epoch 00083: fbeta_score did not improve from 0.67531\n",
      "Epoch 84/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.0479 - fbeta_score: 0.6791\n",
      "\n",
      "Epoch 00084: fbeta_score did not improve from 0.67531\n",
      "Epoch 85/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 54s 227ms/step - loss: 1.0412 - fbeta_score: 0.6827\n",
      "\n",
      "Epoch 00085: fbeta_score did not improve from 0.67531\n",
      "Epoch 86/150\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 1.0311 - fbeta_score: 0.6830\n",
      "\n",
      "Epoch 00086: fbeta_score did not improve from 0.67531\n",
      "Epoch 87/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 1.0048 - fbeta_score: 0.6934\n",
      "\n",
      "Epoch 00087: fbeta_score improved from 0.67531 to 0.67943, saving model to CNN_BiLSTM.h5\n",
      "Epoch 88/150\n",
      "238/238 [==============================] - 54s 226ms/step - loss: 1.0118 - fbeta_score: 0.6890\n",
      "\n",
      "Epoch 00088: fbeta_score improved from 0.67943 to 0.68440, saving model to CNN_BiLSTM.h5\n",
      "Epoch 89/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 1.0111 - fbeta_score: 0.6916\n",
      "\n",
      "Epoch 00089: fbeta_score improved from 0.68440 to 0.68476, saving model to CNN_BiLSTM.h5\n",
      "Epoch 90/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.9984 - fbeta_score: 0.6913\n",
      "\n",
      "Epoch 00090: fbeta_score did not improve from 0.68476\n",
      "Epoch 91/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.0079 - fbeta_score: 0.6929\n",
      "\n",
      "Epoch 00091: fbeta_score did not improve from 0.68476\n",
      "Epoch 92/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 0.9969 - fbeta_score: 0.6931\n",
      "\n",
      "Epoch 00092: fbeta_score improved from 0.68476 to 0.68654, saving model to CNN_BiLSTM.h5\n",
      "Epoch 93/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.9867 - fbeta_score: 0.6939\n",
      "\n",
      "Epoch 00093: fbeta_score improved from 0.68654 to 0.68944, saving model to CNN_BiLSTM.h5\n",
      "Epoch 94/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 0.9795 - fbeta_score: 0.6974\n",
      "\n",
      "Epoch 00094: fbeta_score improved from 0.68944 to 0.69029, saving model to CNN_BiLSTM.h5\n",
      "Epoch 95/150\n",
      "238/238 [==============================] - 55s 232ms/step - loss: 0.9733 - fbeta_score: 0.7007\n",
      "\n",
      "Epoch 00095: fbeta_score improved from 0.69029 to 0.69171, saving model to CNN_BiLSTM.h5\n",
      "Epoch 96/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 0.9698 - fbeta_score: 0.7041\n",
      "\n",
      "Epoch 00096: fbeta_score did not improve from 0.69171\n",
      "Epoch 97/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.9624 - fbeta_score: 0.7030\n",
      "\n",
      "Epoch 00097: fbeta_score improved from 0.69171 to 0.69526, saving model to CNN_BiLSTM.h5\n",
      "Epoch 98/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 0.9609 - fbeta_score: 0.7050\n",
      "\n",
      "Epoch 00098: fbeta_score improved from 0.69526 to 0.69780, saving model to CNN_BiLSTM.h5\n",
      "Epoch 99/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.9441 - fbeta_score: 0.7116\n",
      "\n",
      "Epoch 00099: fbeta_score improved from 0.69780 to 0.70162, saving model to CNN_BiLSTM.h5\n",
      "Epoch 100/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 0.9479 - fbeta_score: 0.7074\n",
      "\n",
      "Epoch 00100: fbeta_score did not improve from 0.70162\n",
      "Epoch 101/150\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 0.9332 - fbeta_score: 0.7079\n",
      "\n",
      "Epoch 00101: fbeta_score did not improve from 0.70162\n",
      "Epoch 102/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.9252 - fbeta_score: 0.7129\n",
      "\n",
      "Epoch 00102: fbeta_score improved from 0.70162 to 0.70366, saving model to CNN_BiLSTM.h5\n",
      "Epoch 103/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 0.9317 - fbeta_score: 0.7111\n",
      "\n",
      "Epoch 00103: fbeta_score improved from 0.70366 to 0.70553, saving model to CNN_BiLSTM.h5\n",
      "Epoch 104/150\n",
      "238/238 [==============================] - 54s 229ms/step - loss: 0.9366 - fbeta_score: 0.7119\n",
      "\n",
      "Epoch 00104: fbeta_score did not improve from 0.70553\n",
      "Epoch 105/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 0.9224 - fbeta_score: 0.7123\n",
      "\n",
      "Epoch 00105: fbeta_score improved from 0.70553 to 0.70586, saving model to CNN_BiLSTM.h5\n",
      "Epoch 106/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 0.9046 - fbeta_score: 0.7164\n",
      "\n",
      "Epoch 00106: fbeta_score improved from 0.70586 to 0.70672, saving model to CNN_BiLSTM.h5\n",
      "Epoch 107/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.9196 - fbeta_score: 0.7118\n",
      "\n",
      "Epoch 00107: fbeta_score improved from 0.70672 to 0.70767, saving model to CNN_BiLSTM.h5\n",
      "Epoch 108/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.9144 - fbeta_score: 0.7134\n",
      "\n",
      "Epoch 00108: fbeta_score improved from 0.70767 to 0.71090, saving model to CNN_BiLSTM.h5\n",
      "Epoch 109/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 0.9023 - fbeta_score: 0.7148\n",
      "\n",
      "Epoch 00109: fbeta_score improved from 0.71090 to 0.71129, saving model to CNN_BiLSTM.h5\n",
      "Epoch 110/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 0.9016 - fbeta_score: 0.7196\n",
      "\n",
      "Epoch 00110: fbeta_score did not improve from 0.71129\n",
      "Epoch 111/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.8770 - fbeta_score: 0.7287\n",
      "\n",
      "Epoch 00111: fbeta_score improved from 0.71129 to 0.71725, saving model to CNN_BiLSTM.h5\n",
      "Epoch 112/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 0.8869 - fbeta_score: 0.7235\n",
      "\n",
      "Epoch 00112: fbeta_score did not improve from 0.71725\n",
      "Epoch 113/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 0.8759 - fbeta_score: 0.7257\n",
      "\n",
      "Epoch 00113: fbeta_score did not improve from 0.71725\n",
      "Epoch 114/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 0.8905 - fbeta_score: 0.7243\n",
      "\n",
      "Epoch 00114: fbeta_score improved from 0.71725 to 0.71975, saving model to CNN_BiLSTM.h5\n",
      "Epoch 115/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.8922 - fbeta_score: 0.7257\n",
      "\n",
      "Epoch 00115: fbeta_score did not improve from 0.71975\n",
      "Epoch 116/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.8779 - fbeta_score: 0.7244\n",
      "\n",
      "Epoch 00116: fbeta_score improved from 0.71975 to 0.72094, saving model to CNN_BiLSTM.h5\n",
      "Epoch 117/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.8558 - fbeta_score: 0.7310\n",
      "\n",
      "Epoch 00117: fbeta_score improved from 0.72094 to 0.72324, saving model to CNN_BiLSTM.h5\n",
      "Epoch 118/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 0.8542 - fbeta_score: 0.7296\n",
      "\n",
      "Epoch 00118: fbeta_score did not improve from 0.72324\n",
      "Epoch 119/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.8817 - fbeta_score: 0.7260\n",
      "\n",
      "Epoch 00119: fbeta_score did not improve from 0.72324\n",
      "Epoch 120/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 0.8514 - fbeta_score: 0.7281\n",
      "\n",
      "Epoch 00120: fbeta_score did not improve from 0.72324\n",
      "Epoch 121/150\n",
      "238/238 [==============================] - 55s 232ms/step - loss: 0.8622 - fbeta_score: 0.7331\n",
      "\n",
      "Epoch 00121: fbeta_score improved from 0.72324 to 0.72608, saving model to CNN_BiLSTM.h5\n",
      "Epoch 122/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.8699 - fbeta_score: 0.7268\n",
      "\n",
      "Epoch 00122: fbeta_score did not improve from 0.72608\n",
      "Epoch 123/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 0.8507 - fbeta_score: 0.7311\n",
      "\n",
      "Epoch 00123: fbeta_score did not improve from 0.72608\n",
      "Epoch 124/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.8490 - fbeta_score: 0.7341\n",
      "\n",
      "Epoch 00124: fbeta_score improved from 0.72608 to 0.72901, saving model to CNN_BiLSTM.h5\n",
      "Epoch 125/150\n",
      "238/238 [==============================] - 55s 229ms/step - loss: 0.8377 - fbeta_score: 0.7328\n",
      "\n",
      "Epoch 00125: fbeta_score did not improve from 0.72901\n",
      "Epoch 126/150\n",
      "238/238 [==============================] - 54s 229ms/step - loss: 0.8483 - fbeta_score: 0.7328\n",
      "\n",
      "Epoch 00126: fbeta_score did not improve from 0.72901\n",
      "Epoch 127/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 0.8185 - fbeta_score: 0.7346\n",
      "\n",
      "Epoch 00127: fbeta_score did not improve from 0.72901\n",
      "Epoch 128/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.8385 - fbeta_score: 0.7368\n",
      "\n",
      "Epoch 00128: fbeta_score improved from 0.72901 to 0.72924, saving model to CNN_BiLSTM.h5\n",
      "Epoch 129/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.8413 - fbeta_score: 0.7341\n",
      "\n",
      "Epoch 00129: fbeta_score improved from 0.72924 to 0.72976, saving model to CNN_BiLSTM.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 0.8412 - fbeta_score: 0.7368\n",
      "\n",
      "Epoch 00130: fbeta_score improved from 0.72976 to 0.73312, saving model to CNN_BiLSTM.h5\n",
      "Epoch 131/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.8085 - fbeta_score: 0.7440\n",
      "\n",
      "Epoch 00131: fbeta_score improved from 0.73312 to 0.73602, saving model to CNN_BiLSTM.h5\n",
      "Epoch 132/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 0.8236 - fbeta_score: 0.7376\n",
      "\n",
      "Epoch 00132: fbeta_score did not improve from 0.73602\n",
      "Epoch 133/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 0.8206 - fbeta_score: 0.7412\n",
      "\n",
      "Epoch 00133: fbeta_score did not improve from 0.73602\n",
      "Epoch 134/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.8118 - fbeta_score: 0.7440\n",
      "\n",
      "Epoch 00134: fbeta_score did not improve from 0.73602\n",
      "Epoch 135/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 0.7929 - fbeta_score: 0.7508\n",
      "\n",
      "Epoch 00135: fbeta_score improved from 0.73602 to 0.73849, saving model to CNN_BiLSTM.h5\n",
      "Epoch 136/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.8121 - fbeta_score: 0.7375\n",
      "\n",
      "Epoch 00136: fbeta_score did not improve from 0.73849\n",
      "Epoch 137/150\n",
      "238/238 [==============================] - 55s 232ms/step - loss: 0.8104 - fbeta_score: 0.7470\n",
      "\n",
      "Epoch 00137: fbeta_score did not improve from 0.73849\n",
      "Epoch 138/150\n",
      "238/238 [==============================] - 54s 227ms/step - loss: 0.7920 - fbeta_score: 0.7497\n",
      "\n",
      "Epoch 00138: fbeta_score improved from 0.73849 to 0.74277, saving model to CNN_BiLSTM.h5\n",
      "Epoch 139/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 0.7927 - fbeta_score: 0.7511\n",
      "\n",
      "Epoch 00139: fbeta_score did not improve from 0.74277\n",
      "Epoch 140/150\n",
      "238/238 [==============================] - 55s 233ms/step - loss: 0.7770 - fbeta_score: 0.7542\n",
      "\n",
      "Epoch 00140: fbeta_score improved from 0.74277 to 0.74385, saving model to CNN_BiLSTM.h5\n",
      "Epoch 141/150\n",
      "238/238 [==============================] - 55s 231ms/step - loss: 0.7852 - fbeta_score: 0.7509\n",
      "\n",
      "Epoch 00141: fbeta_score did not improve from 0.74385\n",
      "Epoch 142/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.7773 - fbeta_score: 0.7531\n",
      "\n",
      "Epoch 00142: fbeta_score improved from 0.74385 to 0.74626, saving model to CNN_BiLSTM.h5\n",
      "Epoch 143/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.7932 - fbeta_score: 0.7469\n",
      "\n",
      "Epoch 00143: fbeta_score did not improve from 0.74626\n",
      "Epoch 144/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.7927 - fbeta_score: 0.7498\n",
      "\n",
      "Epoch 00144: fbeta_score did not improve from 0.74626\n",
      "Epoch 145/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.7864 - fbeta_score: 0.7489\n",
      "\n",
      "Epoch 00145: fbeta_score did not improve from 0.74626\n",
      "Epoch 146/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.7662 - fbeta_score: 0.7560\n",
      "\n",
      "Epoch 00146: fbeta_score improved from 0.74626 to 0.74705, saving model to CNN_BiLSTM.h5\n",
      "Epoch 147/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.7673 - fbeta_score: 0.7557\n",
      "\n",
      "Epoch 00147: fbeta_score improved from 0.74705 to 0.74935, saving model to CNN_BiLSTM.h5\n",
      "Epoch 148/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.7780 - fbeta_score: 0.7503\n",
      "\n",
      "Epoch 00148: fbeta_score did not improve from 0.74935\n",
      "Epoch 149/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.7594 - fbeta_score: 0.7570\n",
      "\n",
      "Epoch 00149: fbeta_score did not improve from 0.74935\n",
      "Epoch 150/150\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 0.7750 - fbeta_score: 0.7503\n",
      "\n",
      "Epoch 00150: fbeta_score did not improve from 0.74935\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=150, callbacks=[early_stopping, model_checkpoint], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
