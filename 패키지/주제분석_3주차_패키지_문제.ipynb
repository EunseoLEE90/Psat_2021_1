{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "주제분석 3주차 패키지 문제.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll1MRXFG1Ecu"
      },
      "source": [
        "# 21-01 주제분석 3주차 패키지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYyEIOPd1Ec0"
      },
      "source": [
        "- 주제분석 3주차 분석 툴은 Python/R 둘 다 가능합니다. \n",
        "    - 1-3주차 패키지 문제의 조건 및 힌트는 Python을 기준으로 하지만, R을 사용해도 무방합니다.\n",
        "    - 다만 2/3주차의 머신러닝/딥러닝 모듈을 편하게 사용하기 위해서는 Python이 더 편할겁니다.\n",
        "\n",
        "- 제출형식은 pdf/html/doc/ppt 등 발표가 가능하면 괜찮습니다. 하지만 html로 주시면 가장 감사합니다.\n",
        "\n",
        "- 패키지 과제 발표는 세미나 쉬는시간 이후에 하게 되며, 역시 랜덤으로 5시00분에 발표됩니다.\n",
        "\n",
        "- 제출기한은 목요일 자정까지이며 지각시 벌금 5000원이 있습니다. 미제출 시 만원입니다. \n",
        "    - 패키지 2회 무단 미제출 시 퇴출이니 유의해 주세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DXl8NHA1rEW",
        "outputId": "271835d0-6822-4d69-a24c-818e2d7f1b7d"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.1.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKp7S_l01Ec1",
        "outputId": "19a511ae-be9e-42ef-ce0f-53df4703fd46"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from category_encoders.cat_boost import CatBoostEncoder\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMModel,LGBMRegressor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwvcNxUR1w5D",
        "outputId": "987e2ef6-e6df-423b-f1cc-df93b977cfbc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NKG5NmN1x0r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22TGbkhL2RGg"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZTXfCsL1Ec1"
      },
      "source": [
        "- 이번주에 다룰 내용은 머신러닝 모델의 해석/기본적인 딥러닝입니다.\n",
        "- 더불어서 다뤄지지는 내용은 randomness control입니다.\n",
        "- 먼저 주어진 코드를 실행하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55zSyCQb1Ec2",
        "outputId": "2d652fde-d2a2-4100-e8a3-cf16cb70839c"
      },
      "source": [
        "train = pd.read_csv('/gdrive/MyDrive/data/train.csv')\n",
        "test=  pd.read_csv('/gdrive/MyDrive/data/test.csv')\n",
        "\n",
        "train_x = train.drop(['price'], axis = 1)\n",
        "train_y = train.loc[:, ['price']]\n",
        "test_x = test.drop(['price'], axis = 1)\n",
        "test_y = np.sqrt(test.loc[:, ['price']])\n",
        "\n",
        "feature_list = list(train_x.columns)\n",
        "\n",
        "CBE_encoder = CatBoostEncoder()\n",
        "train_cbe = CBE_encoder.fit_transform(train_x[feature_list], train_y)\n",
        "test_cbe = CBE_encoder.transform(test_x[feature_list])\n",
        "\n",
        "best_lgbm_reg = LGBMRegressor(learning_rate = 0.3)\n",
        "best_lgbm_reg.fit(train_cbe, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "              importance_type='split', learning_rate=0.3, max_depth=-1,\n",
              "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
              "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "cPJGVBA81Ec3",
        "outputId": "eeba1a23-ed67-415e-8bee-0979ec409c11"
      },
      "source": [
        "test_cbe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dong</th>\n",
              "      <th>apt</th>\n",
              "      <th>exclusive_use_area</th>\n",
              "      <th>floor</th>\n",
              "      <th>transaction_year</th>\n",
              "      <th>until_trans</th>\n",
              "      <th>sin_date</th>\n",
              "      <th>cos_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>91827.227742</td>\n",
              "      <td>89369.051084</td>\n",
              "      <td>70.80</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-1.836970e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>91827.227742</td>\n",
              "      <td>89369.051084</td>\n",
              "      <td>94.51</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>-2.449294e-16</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>91827.227742</td>\n",
              "      <td>89369.051084</td>\n",
              "      <td>160.85</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>-2.449294e-16</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91827.227742</td>\n",
              "      <td>89369.051084</td>\n",
              "      <td>94.51</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>3.061617e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91827.227742</td>\n",
              "      <td>89369.051084</td>\n",
              "      <td>136.40</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>3.061617e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91359</th>\n",
              "      <td>42897.089485</td>\n",
              "      <td>48238.989201</td>\n",
              "      <td>59.72</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>-1.470814e-15</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91360</th>\n",
              "      <td>42897.089485</td>\n",
              "      <td>41180.818678</td>\n",
              "      <td>59.87</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-3.919489e-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91361</th>\n",
              "      <td>42897.089485</td>\n",
              "      <td>41180.818678</td>\n",
              "      <td>84.74</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-3.919489e-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91362</th>\n",
              "      <td>42897.089485</td>\n",
              "      <td>41737.824622</td>\n",
              "      <td>84.74</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-3.919489e-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91363</th>\n",
              "      <td>42897.089485</td>\n",
              "      <td>48238.989201</td>\n",
              "      <td>84.98</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-3.919489e-15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91364 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               dong           apt  ...      sin_date      cos_date\n",
              "0      91827.227742  89369.051084  ... -1.000000e+00 -1.836970e-16\n",
              "1      91827.227742  89369.051084  ... -2.449294e-16  1.000000e+00\n",
              "2      91827.227742  89369.051084  ... -2.449294e-16  1.000000e+00\n",
              "3      91827.227742  89369.051084  ...  1.000000e+00  3.061617e-16\n",
              "4      91827.227742  89369.051084  ...  1.000000e+00  3.061617e-16\n",
              "...             ...           ...  ...           ...           ...\n",
              "91359  42897.089485  48238.989201  ... -1.470814e-15 -1.000000e+00\n",
              "91360  42897.089485  41180.818678  ... -1.000000e+00 -3.919489e-15\n",
              "91361  42897.089485  41180.818678  ... -1.000000e+00 -3.919489e-15\n",
              "91362  42897.089485  41737.824622  ... -1.000000e+00 -3.919489e-15\n",
              "91363  42897.089485  48238.989201  ... -1.000000e+00 -3.919489e-15\n",
              "\n",
              "[91364 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "s1ngunmi1Ec3",
        "outputId": "60934d68-a83b-4e32-bcc0-1309fe6089fc"
      },
      "source": [
        "test_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>258.843582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>298.831056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>331.662479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>293.257566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>342.052628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91359</th>\n",
              "      <td>230.217289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91360</th>\n",
              "      <td>230.217289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91361</th>\n",
              "      <td>237.697286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91362</th>\n",
              "      <td>235.584380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91363</th>\n",
              "      <td>252.487623</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91364 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            price\n",
              "0      258.843582\n",
              "1      298.831056\n",
              "2      331.662479\n",
              "3      293.257566\n",
              "4      342.052628\n",
              "...           ...\n",
              "91359  230.217289\n",
              "91360  230.217289\n",
              "91361  237.697286\n",
              "91362  235.584380\n",
              "91363  252.487623\n",
              "\n",
              "[91364 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDZV6o1w1Ec3"
      },
      "source": [
        "## 1. Interpretable ML\n",
        "\n",
        "해석가능한 머신러닝은 모델의 결과를 해석하기 위한 방법들입니다. 보통 랜덤포레스트(Random Forest)에서 Feature(Variable) Importance에 대해 들어본 적이 있을텐데, 그것과 유사합니다. Interpretable ML 방법의 특징은 어떤 모델에도 다 적용이 가능하다는건데, SVM이나 Neural Net같이 해석이 불가능하다고 알려진 모델들도 어떤 변수들이 모델을 만드는데 있어서 주요하게 사용되었는지를 파악할 수 있게 해줍니다. 물론 회귀분석처럼 '다른 변수들을 고정시킨 상황에서 $x_1$이 한단위 증가하면 $y$가 평균적으로 $\\beta_1$만큼 증가한다' 라고 말할수는 없지만요!\n",
        "\n",
        "Feature Importance/Partial Dependence Plot/Lime/SHAP 에 대한 해석은 조금 조심해야할 필요가 있습니다. 밑의 링크의 '모델해석 및 이탈원인 분석'을 참고하면 되는데, 처음에 딱 이해하기 쉬운 개념은 아니지만 나중에 보다보면 더 이해가 잘 되실 것 같아요.\n",
        "\n",
        "https://danbi-ncsoft.github.io/competition/2019/02/19/big-contest-2018-retrospect.html\n",
        "\n",
        "나중에 관심있으시면 이 책을 보는 것을 추천드립니다. 저도 아직 안봄 ㅎ\n",
        "\n",
        "https://christophm.github.io/interpretable-ml-book/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdQg5Vng1Ec4"
      },
      "source": [
        "#### **오늘의 해석은 각각 방법에 입각해서 엄밀하게 해석할 필요없이, 그냥 가볍게 해석해주시면 됩니다!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJShRJQA1Ec4"
      },
      "source": [
        "### 1.1 모델 불러오기\n",
        "\n",
        "주어진 패키지를 불러오고, `lgbm.pkl`을 불러오세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_drfyQL1Ec4"
      },
      "source": [
        "import pickle\n",
        "import joblib\n",
        "lgbm_pickle = joblib.load('/gdrive/MyDrive/data/lgbm.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOVFIBpo1Ec4"
      },
      "source": [
        "### 1.2 Feature Importance 확인과 해석\n",
        "\n",
        "- 불러온 모델에 대해 `plot_importance`함수를 통해 Feature Importance를 시각화해주세요.\n",
        "- 결과에 대해 간단히 해석해주세요.\n",
        "\n",
        "여기서 Feature Importance는 Permutation를 통한 중요도를 보는 것이 아니고, tree 모델 자체의 구성에서 어떤 변수가 지니불순도를 잘 줄였는지를 확인한 것이라고 이해해주시면 됩니다. \n",
        "\n",
        "(모델의 피처 중 어느 피처가 가장 중요한지 나타내는 기법이다.\n",
        "특정 피처의 값을 임의의 값으로 치환했을 때 원본보다 에러가 얼마나 더 커지는지를 판단하여 중요도를 측정한다.\n",
        "단, 음양의 방향이 없고, scale에 따라 모델에 미치는 영향 파악이 어려우며, 피처 간 의존성 존재 시 신뢰할 수 없다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8Hfvkn81Ec5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bfp8WZOx1Ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "ec6fc46c-02c3-4c17-da40-01926ef0d499"
      },
      "source": [
        "from lightgbm import plot_importance\n",
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "plot_importance(lgbm_pickle, ax=ax)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f47594cc750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWt9niMT1Ec5"
      },
      "source": [
        "피쳐중요도는 exclusive_use_area가 제일 높고,dong,apt,until_trans 순이다. \n",
        "위의 4가지의 피처를 선택하는 것이 좋을 것 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbyxiB4r1Ec5",
        "outputId": "481325c2-3b45-4067-9030-6e6acfcc2c20"
      },
      "source": [
        "best_lgbm_reg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(learning_rate=0.3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-HYOqbC1Ec6"
      },
      "source": [
        "**이제는 불러온 모델 말고, `best_lgbm_reg`를 사용하세요.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJgdUYTk1Ec6"
      },
      "source": [
        "### 1.3 Randomness Control\n",
        "\n",
        "- `random, numpy` 패키지의 난수를 42로 고정하세요.\n",
        "- 더불어서 `os` 패키지의 난수도 고정해야합니다.\n",
        "\n",
        "Permutation 방식의 Feature Importance를 시행한건데, permutation자체에 랜덤성이 있다보니 결과가 재현 가능하도록 시드를 고정해줍니다.\n",
        "\n",
        "파이썬의 시드 고정은 R처럼 그냥 `set.seed()`한다고 해서 고정되지 않습니다. 전체 파이썬과 여러 패키지들의 randomness를 각각 고정해주어야 재현가능해집니다. 정말 귀찮고, 딥러닝의 경우 GPU를 사용할 경우 GPU의 계산과 관련된 시드를 고정하면 속도가 상당히 느려진다고 알려져 있습니다. 더불어서 재현도 100%되진 않으며 성능도 살짝 떨어진다고는 하지만, GPU를 사용하지 않는 경우에는 문제가 없고 최소한 할줄은 알아야겠죠?\n",
        "\n",
        "더불어서 왜 저런식으로 복잡하게 구성이 되는가?에 대해 궁금할 수 있는데 찾아본 적은 없지만 아마도 `numpy`는 c++가 뒤에서 연산을 해주는 것으로 알고있고(그래서 빠름!), `random`은 그냥 파이썬이고, `os`는 우리 os를 건드리는 것이 아닐까....? 추측입니다 :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGRN5slv1Ec6"
      },
      "source": [
        "import random\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czFOuq6t1Ec6"
      },
      "source": [
        "np.random.seed(42)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eueklKc-1Ec6"
      },
      "source": [
        "### 1.4 Permutation Feature Importance\n",
        "\n",
        "- permutation feature importance를 계산하기 위해 `best_lgbm_reg`를 `permutation_importance`함수를 사용해 test set에 적합하세요.\n",
        "- permutation feature importance를 시각화해주세요.\n",
        "\n",
        "위의 1.2에서는 train에서 변수중요도를 보고, 지금은 test에서 봐서 좀 이상하다고 생각할수도 있습니다. 편의를 위해, 그리고 실제로 변수중요도에 대한 부분에서 어떤 set에 대해 봐야하는지가 100% 정답처럼 있는 것은 아니라고 알고 있어요.(물론 제가 틀렸을수도!) 아무튼 너무 신경쓰지말고 해주세요!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN6pVBU61Ec7"
      },
      "source": [
        "from sklearn.inspection import permutation_importance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlLEWMm-1Ec7"
      },
      "source": [
        "result = permutation_importance(best_lgbm_reg, test_cbe, test_y, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-aOdV_1Ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "7c9f1d41-0706-40f1-eaac-469fdece20f5"
      },
      "source": [
        "vis=pd.DataFrame({'feature':feature_list,'importance':result.importances_mean})\n",
        "vis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dong</td>\n",
              "      <td>-126811.130132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apt</td>\n",
              "      <td>-139385.867696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>exclusive_use_area</td>\n",
              "      <td>-153106.487880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>floor</td>\n",
              "      <td>-13477.364741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>transaction_year</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>until_trans</td>\n",
              "      <td>-51303.436419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>sin_date</td>\n",
              "      <td>1260.434312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>cos_date</td>\n",
              "      <td>819.190059</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              feature     importance\n",
              "0                dong -126811.130132\n",
              "1                 apt -139385.867696\n",
              "2  exclusive_use_area -153106.487880\n",
              "3               floor  -13477.364741\n",
              "4    transaction_year       0.000000\n",
              "5         until_trans  -51303.436419\n",
              "6            sin_date    1260.434312\n",
              "7            cos_date     819.190059"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "4jVzh_omg6FL",
        "outputId": "f853befe-4d23-4152-ee0f-df2b503c3059"
      },
      "source": [
        "sns.barplot(x=vis['feature'],y=vis['importance'],data=vis)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol1S0pge1Ec7"
      },
      "source": [
        "### 1.5 SHAP(SHapley Additive exPlanations)의 확인과 해석\n",
        "\n",
        "- SHAP Value를 구하고 간단한 해석을 해주세요.\n",
        "- `shap.TreeExplainer`, `shap_values`, `shap.summary_plot` 정도의 함수만 사용하면 됩니다.\n",
        "- 결과가 좀 다른건 상관없습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4Prwjje1Ec7"
      },
      "source": [
        "#! pip install shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TzwcljG1Ec8"
      },
      "source": [
        "import shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acUeDuIX1Ec8"
      },
      "source": [
        "explainer = shap.TreeExplainer(best_lgbm_reg) # Tree model Shap Value 확인 객체 지정\n",
        "shap_values = explainer.shap_values(test_cbe) # Shap Values 계산"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGnJkPPV1Ec8",
        "outputId": "1a772104-601c-4c0c-fa15-88e7cf7cdfbe"
      },
      "source": [
        "shap.summary_plot(shap_values, test_cbe)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Glyph 8722 missing from current font.\n",
            "Glyph 8722 missing from current font.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x338.4 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np-2-Mya1Ec8"
      },
      "source": [
        "apt: 변수의 값이 높을수록 price가 높은 양의 경향성이 있다\n",
        "dong: 변수의 값이 높을수록 price가 높은 양의 경향성이 있다\n",
        "exclusive_use_area:변수의 값이 높을수록 price가 높은 양의 경향성이 있다\n",
        "transaction_year: 변수의 값이 높을수록 price가 낮은 음의 경향성이 있다\n",
        "until_trans: 애매\n",
        "floor:  변수의 값이 높을수록 price가 높은 양의 경향성이 있다\n",
        "sin_date:\n",
        "cos_date:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKKcgklu1Ec9"
      },
      "source": [
        "## 2. 딥러닝 기본\n",
        "\n",
        "딥러닝 정말 간단히 해볼겁니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-A2wVcw1Ec9"
      },
      "source": [
        "### 2.1 주어진 코드를 실행하고, 현재 신경망의 구조에 대해 간단히 설명해주세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1zE3W_r1Ec9"
      },
      "source": [
        "train = pd.read_csv('/gdrive/MyDrive/data/train.csv')\n",
        "train_x = train.drop(['price'], axis = 1)\n",
        "train_y = train.loc[:, ['price']]\n",
        "\n",
        "val_x = train_x[train['transaction_year'] == 4]\n",
        "val_y = train_y[train['transaction_year'] == 4]\n",
        "train_tune_x = train_x[train['transaction_year'] < 4]\n",
        "train_tune_y = train_y[train['transaction_year'] < 4]\n",
        "\n",
        "CBE_encoder = CatBoostEncoder()\n",
        "train_tune_cbe = CBE_encoder.fit_transform(train_tune_x[feature_list], train_tune_y)\n",
        "val_cbe = CBE_encoder.transform(val_x[feature_list])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6zAVgiz1Ec9"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpSboP_41Ec9"
      },
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(256, activation='relu', input_shape=[len(train_tune_cbe.keys())]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.0001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mse'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3pJMvQB1Ec-",
        "outputId": "e350b9cb-1025-4e80-d37a-6cc7bd70fb1d"
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 256)               2304      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 20,865\n",
            "Trainable params: 20,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMjHd-hN3S28"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj9iOZdo33dz"
      },
      "source": [
        "완전연결계층 4개로 이루어진 모델, output이 256,64,32,1로 나오는 모델. 입력층과 출력층의 간선의 수인 파라미터는 2304,16448,2080,33개."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUpSB6K21Ec-"
      },
      "source": [
        "### 2.2 training loss와 validation loss를 시각화하세요.\n",
        "\n",
        "- 본인 컴에서 돌리면 꽤나 돌아갈수도 있어요. 주분과 함께하려면 패키지가 코랩으로 가거나, 주분이 코랩으로 가면 한번에 투 컴을 돌릴 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5A-SDzZ1Ec-",
        "outputId": "8aa1c6a4-cf37-4d1d-8e2d-800e632115fa"
      },
      "source": [
        "history = model.fit(train_tune_cbe, train_tune_y, epochs=300, validation_data = (val_cbe, val_y), batch_size = 512)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "611/611 [==============================] - 5s 6ms/step - loss: 1158946824.6797 - mse: 1158946824.6797 - val_loss: 353897952.0000 - val_mse: 353897952.0000\n",
            "Epoch 2/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 236818238.0915 - mse: 236818238.0915 - val_loss: 353941280.0000 - val_mse: 353941280.0000\n",
            "Epoch 3/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 236517058.4837 - mse: 236517058.4837 - val_loss: 361226240.0000 - val_mse: 361226240.0000\n",
            "Epoch 4/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 232124104.1046 - mse: 232124104.1046 - val_loss: 342958656.0000 - val_mse: 342958656.0000\n",
            "Epoch 5/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 227027085.0458 - mse: 227027085.0458 - val_loss: 355207392.0000 - val_mse: 355207392.0000\n",
            "Epoch 6/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 225501267.6078 - mse: 225501267.6078 - val_loss: 350845856.0000 - val_mse: 350845856.0000\n",
            "Epoch 7/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 225501826.8758 - mse: 225501826.8758 - val_loss: 343341696.0000 - val_mse: 343341696.0000\n",
            "Epoch 8/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 222140765.2810 - mse: 222140765.2810 - val_loss: 340923328.0000 - val_mse: 340923328.0000\n",
            "Epoch 9/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 225955173.0719 - mse: 225955173.0719 - val_loss: 351182016.0000 - val_mse: 351182016.0000\n",
            "Epoch 10/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 233447536.5752 - mse: 233447536.5752 - val_loss: 329795008.0000 - val_mse: 329795008.0000\n",
            "Epoch 11/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 236580804.9412 - mse: 236580804.9412 - val_loss: 326768096.0000 - val_mse: 326768096.0000\n",
            "Epoch 12/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 226889386.6667 - mse: 226889386.6667 - val_loss: 334837536.0000 - val_mse: 334837536.0000\n",
            "Epoch 13/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 234453818.2745 - mse: 234453818.2745 - val_loss: 326035040.0000 - val_mse: 326035040.0000\n",
            "Epoch 14/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 228708511.2418 - mse: 228708511.2418 - val_loss: 334380032.0000 - val_mse: 334380032.0000\n",
            "Epoch 15/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 231345305.0458 - mse: 231345305.0458 - val_loss: 335677312.0000 - val_mse: 335677312.0000\n",
            "Epoch 16/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 233512723.4248 - mse: 233512723.4248 - val_loss: 319312384.0000 - val_mse: 319312384.0000\n",
            "Epoch 17/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 226568814.1438 - mse: 226568814.1438 - val_loss: 332477312.0000 - val_mse: 332477312.0000\n",
            "Epoch 18/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 222649885.8039 - mse: 222649885.8039 - val_loss: 340248640.0000 - val_mse: 340248640.0000\n",
            "Epoch 19/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 223068421.2810 - mse: 223068421.2810 - val_loss: 358189440.0000 - val_mse: 358189440.0000\n",
            "Epoch 20/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 225233639.4248 - mse: 225233639.4248 - val_loss: 332588992.0000 - val_mse: 332588992.0000\n",
            "Epoch 21/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 220641355.6863 - mse: 220641355.6863 - val_loss: 348873280.0000 - val_mse: 348873280.0000\n",
            "Epoch 22/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 222717731.0327 - mse: 222717731.0327 - val_loss: 308135264.0000 - val_mse: 308135264.0000\n",
            "Epoch 23/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 224238460.0000 - mse: 224238460.0000 - val_loss: 304620928.0000 - val_mse: 304620928.0000\n",
            "Epoch 24/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 219768433.3072 - mse: 219768433.3072 - val_loss: 375954528.0000 - val_mse: 375954528.0000\n",
            "Epoch 25/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 221843844.6797 - mse: 221843844.6797 - val_loss: 355566432.0000 - val_mse: 355566432.0000\n",
            "Epoch 26/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 218175267.4248 - mse: 218175267.4248 - val_loss: 295912992.0000 - val_mse: 295912992.0000\n",
            "Epoch 27/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 216127018.7712 - mse: 216127018.7712 - val_loss: 374645120.0000 - val_mse: 374645120.0000\n",
            "Epoch 28/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 210929446.6405 - mse: 210929446.6405 - val_loss: 295611456.0000 - val_mse: 295611456.0000\n",
            "Epoch 29/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 205308077.4641 - mse: 205308077.4641 - val_loss: 296307168.0000 - val_mse: 296307168.0000\n",
            "Epoch 30/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 213654117.7516 - mse: 213654117.7516 - val_loss: 344527840.0000 - val_mse: 344527840.0000\n",
            "Epoch 31/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 213676211.8431 - mse: 213676211.8431 - val_loss: 345768032.0000 - val_mse: 345768032.0000\n",
            "Epoch 32/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 200439997.5425 - mse: 200439997.5425 - val_loss: 348997696.0000 - val_mse: 348997696.0000\n",
            "Epoch 33/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 197003393.4118 - mse: 197003393.4118 - val_loss: 321756160.0000 - val_mse: 321756160.0000\n",
            "Epoch 34/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 201392408.2876 - mse: 201392408.2876 - val_loss: 357171232.0000 - val_mse: 357171232.0000\n",
            "Epoch 35/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 204790687.7386 - mse: 204790687.7386 - val_loss: 293384672.0000 - val_mse: 293384672.0000\n",
            "Epoch 36/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 202630009.5425 - mse: 202630009.5425 - val_loss: 341999168.0000 - val_mse: 341999168.0000\n",
            "Epoch 37/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 199124950.7451 - mse: 199124950.7451 - val_loss: 325181184.0000 - val_mse: 325181184.0000\n",
            "Epoch 38/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 195776586.5882 - mse: 195776586.5882 - val_loss: 316933376.0000 - val_mse: 316933376.0000\n",
            "Epoch 39/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 204397159.9216 - mse: 204397159.9216 - val_loss: 304147808.0000 - val_mse: 304147808.0000\n",
            "Epoch 40/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 194649516.3007 - mse: 194649516.3007 - val_loss: 325100288.0000 - val_mse: 325100288.0000\n",
            "Epoch 41/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 203340150.4837 - mse: 203340150.4837 - val_loss: 362305312.0000 - val_mse: 362305312.0000\n",
            "Epoch 42/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 197842797.6993 - mse: 197842797.6993 - val_loss: 342248608.0000 - val_mse: 342248608.0000\n",
            "Epoch 43/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 198354422.3007 - mse: 198354422.3007 - val_loss: 283993440.0000 - val_mse: 283993440.0000\n",
            "Epoch 44/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 196665782.5621 - mse: 196665782.5621 - val_loss: 296982464.0000 - val_mse: 296982464.0000\n",
            "Epoch 45/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 198466319.6340 - mse: 198466319.6340 - val_loss: 363706272.0000 - val_mse: 363706272.0000\n",
            "Epoch 46/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 193067773.9085 - mse: 193067773.9085 - val_loss: 341268512.0000 - val_mse: 341268512.0000\n",
            "Epoch 47/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 202503255.5033 - mse: 202503255.5033 - val_loss: 354135136.0000 - val_mse: 354135136.0000\n",
            "Epoch 48/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 193547025.7255 - mse: 193547025.7255 - val_loss: 281216352.0000 - val_mse: 281216352.0000\n",
            "Epoch 49/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 192635016.9412 - mse: 192635016.9412 - val_loss: 310696128.0000 - val_mse: 310696128.0000\n",
            "Epoch 50/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 192674794.2222 - mse: 192674794.2222 - val_loss: 328872992.0000 - val_mse: 328872992.0000\n",
            "Epoch 51/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 193424802.3529 - mse: 193424802.3529 - val_loss: 292557344.0000 - val_mse: 292557344.0000\n",
            "Epoch 52/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 187930208.1046 - mse: 187930208.1046 - val_loss: 261757808.0000 - val_mse: 261757808.0000\n",
            "Epoch 53/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 203624324.3922 - mse: 203624324.3922 - val_loss: 275120800.0000 - val_mse: 275120800.0000\n",
            "Epoch 54/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 196360018.4575 - mse: 196360018.4575 - val_loss: 270843264.0000 - val_mse: 270843264.0000\n",
            "Epoch 55/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 195130271.2941 - mse: 195130271.2941 - val_loss: 260004400.0000 - val_mse: 260004400.0000\n",
            "Epoch 56/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 188872068.0784 - mse: 188872068.0784 - val_loss: 269053024.0000 - val_mse: 269053024.0000\n",
            "Epoch 57/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 193167327.9216 - mse: 193167327.9216 - val_loss: 301957184.0000 - val_mse: 301957184.0000\n",
            "Epoch 58/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 190066712.8889 - mse: 190066712.8889 - val_loss: 368019200.0000 - val_mse: 368019200.0000\n",
            "Epoch 59/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 187927285.7255 - mse: 187927285.7255 - val_loss: 322735616.0000 - val_mse: 322735616.0000\n",
            "Epoch 60/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 189978250.7974 - mse: 189978250.7974 - val_loss: 306769984.0000 - val_mse: 306769984.0000\n",
            "Epoch 61/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 199239653.7516 - mse: 199239653.7516 - val_loss: 362558400.0000 - val_mse: 362558400.0000\n",
            "Epoch 62/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 188645710.3529 - mse: 188645710.3529 - val_loss: 319428864.0000 - val_mse: 319428864.0000\n",
            "Epoch 63/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 183428435.1895 - mse: 183428435.1895 - val_loss: 326227360.0000 - val_mse: 326227360.0000\n",
            "Epoch 64/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 192203971.6732 - mse: 192203971.6732 - val_loss: 307039040.0000 - val_mse: 307039040.0000\n",
            "Epoch 65/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 190921723.4248 - mse: 190921723.4248 - val_loss: 301141728.0000 - val_mse: 301141728.0000\n",
            "Epoch 66/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 187737949.2810 - mse: 187737949.2810 - val_loss: 255960544.0000 - val_mse: 255960544.0000\n",
            "Epoch 67/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 192423264.8758 - mse: 192423264.8758 - val_loss: 255566528.0000 - val_mse: 255566528.0000\n",
            "Epoch 68/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 190416268.3660 - mse: 190416268.3660 - val_loss: 364575136.0000 - val_mse: 364575136.0000\n",
            "Epoch 69/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 193453198.1438 - mse: 193453198.1438 - val_loss: 333243552.0000 - val_mse: 333243552.0000\n",
            "Epoch 70/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 185976595.4248 - mse: 185976595.4248 - val_loss: 269007136.0000 - val_mse: 269007136.0000\n",
            "Epoch 71/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 184832872.6275 - mse: 184832872.6275 - val_loss: 260119136.0000 - val_mse: 260119136.0000\n",
            "Epoch 72/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 193864336.2614 - mse: 193864336.2614 - val_loss: 284916832.0000 - val_mse: 284916832.0000\n",
            "Epoch 73/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 190296024.1307 - mse: 190296024.1307 - val_loss: 261306592.0000 - val_mse: 261306592.0000\n",
            "Epoch 74/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 184984671.0850 - mse: 184984671.0850 - val_loss: 320817376.0000 - val_mse: 320817376.0000\n",
            "Epoch 75/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 189820562.4837 - mse: 189820562.4837 - val_loss: 306272128.0000 - val_mse: 306272128.0000\n",
            "Epoch 76/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 184828270.3791 - mse: 184828270.3791 - val_loss: 327424480.0000 - val_mse: 327424480.0000\n",
            "Epoch 77/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 183925355.3203 - mse: 183925355.3203 - val_loss: 250982768.0000 - val_mse: 250982768.0000\n",
            "Epoch 78/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 189547982.5359 - mse: 189547982.5359 - val_loss: 290954400.0000 - val_mse: 290954400.0000\n",
            "Epoch 79/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 183836656.4706 - mse: 183836656.4706 - val_loss: 315149504.0000 - val_mse: 315149504.0000\n",
            "Epoch 80/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 183056064.6275 - mse: 183056064.6275 - val_loss: 263652544.0000 - val_mse: 263652544.0000\n",
            "Epoch 81/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 180509974.5359 - mse: 180509974.5359 - val_loss: 305616160.0000 - val_mse: 305616160.0000\n",
            "Epoch 82/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 182037350.1438 - mse: 182037350.1438 - val_loss: 253420160.0000 - val_mse: 253420160.0000\n",
            "Epoch 83/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 178699415.6601 - mse: 178699415.6601 - val_loss: 278838816.0000 - val_mse: 278838816.0000\n",
            "Epoch 84/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 183276537.2288 - mse: 183276537.2288 - val_loss: 257971856.0000 - val_mse: 257971856.0000\n",
            "Epoch 85/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 184559844.2876 - mse: 184559844.2876 - val_loss: 253517824.0000 - val_mse: 253517824.0000\n",
            "Epoch 86/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 182817208.9673 - mse: 182817208.9673 - val_loss: 402497440.0000 - val_mse: 402497440.0000\n",
            "Epoch 87/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 183481281.8562 - mse: 183481281.8562 - val_loss: 320710272.0000 - val_mse: 320710272.0000\n",
            "Epoch 88/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 182904579.3725 - mse: 182904579.3725 - val_loss: 316456576.0000 - val_mse: 316456576.0000\n",
            "Epoch 89/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 182340591.8693 - mse: 182340591.8693 - val_loss: 267180720.0000 - val_mse: 267180720.0000\n",
            "Epoch 90/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 182916746.1699 - mse: 182916746.1699 - val_loss: 384534592.0000 - val_mse: 384534592.0000\n",
            "Epoch 91/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 185161801.3595 - mse: 185161801.3595 - val_loss: 295268640.0000 - val_mse: 295268640.0000\n",
            "Epoch 92/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 178354705.6732 - mse: 178354705.6732 - val_loss: 327590208.0000 - val_mse: 327590208.0000\n",
            "Epoch 93/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 183794267.0065 - mse: 183794267.0065 - val_loss: 307441280.0000 - val_mse: 307441280.0000\n",
            "Epoch 94/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 178026843.3725 - mse: 178026843.3725 - val_loss: 377370080.0000 - val_mse: 377370080.0000\n",
            "Epoch 95/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 185796446.1176 - mse: 185796446.1176 - val_loss: 329911168.0000 - val_mse: 329911168.0000\n",
            "Epoch 96/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 181034833.2418 - mse: 181034833.2418 - val_loss: 355998624.0000 - val_mse: 355998624.0000\n",
            "Epoch 97/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 182792101.8562 - mse: 182792101.8562 - val_loss: 342646464.0000 - val_mse: 342646464.0000\n",
            "Epoch 98/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 186070871.9739 - mse: 186070871.9739 - val_loss: 364048640.0000 - val_mse: 364048640.0000\n",
            "Epoch 99/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 179623239.6601 - mse: 179623239.6601 - val_loss: 260696304.0000 - val_mse: 260696304.0000\n",
            "Epoch 100/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 178380448.4967 - mse: 178380448.4967 - val_loss: 253296496.0000 - val_mse: 253296496.0000\n",
            "Epoch 101/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 182547911.9216 - mse: 182547911.9216 - val_loss: 319149408.0000 - val_mse: 319149408.0000\n",
            "Epoch 102/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 182073811.7908 - mse: 182073811.7908 - val_loss: 279931936.0000 - val_mse: 279931936.0000\n",
            "Epoch 103/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 178149643.8954 - mse: 178149643.8954 - val_loss: 300701856.0000 - val_mse: 300701856.0000\n",
            "Epoch 104/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 183211252.7320 - mse: 183211252.7320 - val_loss: 300586752.0000 - val_mse: 300586752.0000\n",
            "Epoch 105/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 178522430.1961 - mse: 178522430.1961 - val_loss: 280913824.0000 - val_mse: 280913824.0000\n",
            "Epoch 106/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 183101378.1176 - mse: 183101378.1176 - val_loss: 296057024.0000 - val_mse: 296057024.0000\n",
            "Epoch 107/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 178906143.3725 - mse: 178906143.3725 - val_loss: 355208896.0000 - val_mse: 355208896.0000\n",
            "Epoch 108/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 181766387.3203 - mse: 181766387.3203 - val_loss: 272361472.0000 - val_mse: 272361472.0000\n",
            "Epoch 109/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 179906377.1503 - mse: 179906377.1503 - val_loss: 303927392.0000 - val_mse: 303927392.0000\n",
            "Epoch 110/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 175910713.1373 - mse: 175910713.1373 - val_loss: 310581440.0000 - val_mse: 310581440.0000\n",
            "Epoch 111/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 178328972.2092 - mse: 178328972.2092 - val_loss: 275410784.0000 - val_mse: 275410784.0000\n",
            "Epoch 112/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 183510545.3595 - mse: 183510545.3595 - val_loss: 281819680.0000 - val_mse: 281819680.0000\n",
            "Epoch 113/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 176787959.1895 - mse: 176787959.1895 - val_loss: 301779104.0000 - val_mse: 301779104.0000\n",
            "Epoch 114/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 174747261.0196 - mse: 174747261.0196 - val_loss: 302579392.0000 - val_mse: 302579392.0000\n",
            "Epoch 115/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 182650644.3137 - mse: 182650644.3137 - val_loss: 267955312.0000 - val_mse: 267955312.0000\n",
            "Epoch 116/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 176725435.0719 - mse: 176725435.0719 - val_loss: 286319296.0000 - val_mse: 286319296.0000\n",
            "Epoch 117/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 179725770.0131 - mse: 179725770.0131 - val_loss: 286877312.0000 - val_mse: 286877312.0000\n",
            "Epoch 118/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 176263245.1242 - mse: 176263245.1242 - val_loss: 320566496.0000 - val_mse: 320566496.0000\n",
            "Epoch 119/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 179414981.8954 - mse: 179414981.8954 - val_loss: 306663200.0000 - val_mse: 306663200.0000\n",
            "Epoch 120/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 180257396.5752 - mse: 180257396.5752 - val_loss: 327689152.0000 - val_mse: 327689152.0000\n",
            "Epoch 121/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 178115227.0588 - mse: 178115227.0588 - val_loss: 331447232.0000 - val_mse: 331447232.0000\n",
            "Epoch 122/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 177601331.2941 - mse: 177601331.2941 - val_loss: 311949632.0000 - val_mse: 311949632.0000\n",
            "Epoch 123/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 178055635.0196 - mse: 178055635.0196 - val_loss: 260954736.0000 - val_mse: 260954736.0000\n",
            "Epoch 124/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 176289456.9150 - mse: 176289456.9150 - val_loss: 295254432.0000 - val_mse: 295254432.0000\n",
            "Epoch 125/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 184874058.1176 - mse: 184874058.1176 - val_loss: 303328864.0000 - val_mse: 303328864.0000\n",
            "Epoch 126/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 174407334.0131 - mse: 174407334.0131 - val_loss: 325353312.0000 - val_mse: 325353312.0000\n",
            "Epoch 127/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 173852839.2680 - mse: 173852839.2680 - val_loss: 335905472.0000 - val_mse: 335905472.0000\n",
            "Epoch 128/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 177145523.8954 - mse: 177145523.8954 - val_loss: 274177056.0000 - val_mse: 274177056.0000\n",
            "Epoch 129/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 178300381.3333 - mse: 178300381.3333 - val_loss: 342548832.0000 - val_mse: 342548832.0000\n",
            "Epoch 130/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 182507219.3333 - mse: 182507219.3333 - val_loss: 305869664.0000 - val_mse: 305869664.0000\n",
            "Epoch 131/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 170865507.5294 - mse: 170865507.5294 - val_loss: 322870528.0000 - val_mse: 322870528.0000\n",
            "Epoch 132/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 188029341.8039 - mse: 188029341.8039 - val_loss: 260611648.0000 - val_mse: 260611648.0000\n",
            "Epoch 133/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 175187435.8431 - mse: 175187435.8431 - val_loss: 303497920.0000 - val_mse: 303497920.0000\n",
            "Epoch 134/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 177513398.7451 - mse: 177513398.7451 - val_loss: 238132144.0000 - val_mse: 238132144.0000\n",
            "Epoch 135/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 182359278.2484 - mse: 182359278.2484 - val_loss: 333779264.0000 - val_mse: 333779264.0000\n",
            "Epoch 136/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 171476747.2157 - mse: 171476747.2157 - val_loss: 316082336.0000 - val_mse: 316082336.0000\n",
            "Epoch 137/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 176659370.3137 - mse: 176659370.3137 - val_loss: 289708704.0000 - val_mse: 289708704.0000\n",
            "Epoch 138/300\n",
            "611/611 [==============================] - 4s 6ms/step - loss: 175910682.7843 - mse: 175910682.7843 - val_loss: 254213264.0000 - val_mse: 254213264.0000\n",
            "Epoch 139/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 171121653.9346 - mse: 171121653.9346 - val_loss: 339584928.0000 - val_mse: 339584928.0000\n",
            "Epoch 140/300\n",
            "611/611 [==============================] - 4s 6ms/step - loss: 175772543.1634 - mse: 175772543.1634 - val_loss: 350919520.0000 - val_mse: 350919520.0000\n",
            "Epoch 141/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 174304680.1176 - mse: 174304680.1176 - val_loss: 289957728.0000 - val_mse: 289957728.0000\n",
            "Epoch 142/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 184589294.6013 - mse: 184589294.6013 - val_loss: 246864704.0000 - val_mse: 246864704.0000\n",
            "Epoch 143/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 171159447.7647 - mse: 171159447.7647 - val_loss: 281142400.0000 - val_mse: 281142400.0000\n",
            "Epoch 144/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 179100123.9477 - mse: 179100123.9477 - val_loss: 308722176.0000 - val_mse: 308722176.0000\n",
            "Epoch 145/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 176236876.4444 - mse: 176236876.4444 - val_loss: 332755712.0000 - val_mse: 332755712.0000\n",
            "Epoch 146/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 177956518.9804 - mse: 177956518.9804 - val_loss: 271262496.0000 - val_mse: 271262496.0000\n",
            "Epoch 147/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 179796139.9869 - mse: 179796139.9869 - val_loss: 379067808.0000 - val_mse: 379067808.0000\n",
            "Epoch 148/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 174416965.7778 - mse: 174416965.7778 - val_loss: 270582400.0000 - val_mse: 270582400.0000\n",
            "Epoch 149/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 179768314.6667 - mse: 179768314.6667 - val_loss: 290130656.0000 - val_mse: 290130656.0000\n",
            "Epoch 150/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 174787623.3595 - mse: 174787623.3595 - val_loss: 347117088.0000 - val_mse: 347117088.0000\n",
            "Epoch 151/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 173939609.5686 - mse: 173939609.5686 - val_loss: 255785056.0000 - val_mse: 255785056.0000\n",
            "Epoch 152/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 172674956.1830 - mse: 172674956.1830 - val_loss: 280288480.0000 - val_mse: 280288480.0000\n",
            "Epoch 153/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 171993071.4510 - mse: 171993071.4510 - val_loss: 387641728.0000 - val_mse: 387641728.0000\n",
            "Epoch 154/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 181330723.1895 - mse: 181330723.1895 - val_loss: 319109376.0000 - val_mse: 319109376.0000\n",
            "Epoch 155/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 174364893.7516 - mse: 174364893.7516 - val_loss: 296824320.0000 - val_mse: 296824320.0000\n",
            "Epoch 156/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 176351644.9020 - mse: 176351644.9020 - val_loss: 332603968.0000 - val_mse: 332603968.0000\n",
            "Epoch 157/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 174143985.6471 - mse: 174143985.6471 - val_loss: 309879008.0000 - val_mse: 309879008.0000\n",
            "Epoch 158/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 179382250.4052 - mse: 179382250.4052 - val_loss: 427762144.0000 - val_mse: 427762144.0000\n",
            "Epoch 159/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 174050127.0065 - mse: 174050127.0065 - val_loss: 361783680.0000 - val_mse: 361783680.0000\n",
            "Epoch 160/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 173361076.3660 - mse: 173361076.3660 - val_loss: 255063488.0000 - val_mse: 255063488.0000\n",
            "Epoch 161/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 176824737.3856 - mse: 176824737.3856 - val_loss: 239883536.0000 - val_mse: 239883536.0000\n",
            "Epoch 162/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 178814506.1176 - mse: 178814506.1176 - val_loss: 250810864.0000 - val_mse: 250810864.0000\n",
            "Epoch 163/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 175907891.7124 - mse: 175907891.7124 - val_loss: 254725984.0000 - val_mse: 254725984.0000\n",
            "Epoch 164/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 178567655.1373 - mse: 178567655.1373 - val_loss: 269760512.0000 - val_mse: 269760512.0000\n",
            "Epoch 165/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 171307928.0000 - mse: 171307928.0000 - val_loss: 299981024.0000 - val_mse: 299981024.0000\n",
            "Epoch 166/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 177942348.7712 - mse: 177942348.7712 - val_loss: 332934720.0000 - val_mse: 332934720.0000\n",
            "Epoch 167/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 178729884.9935 - mse: 178729884.9935 - val_loss: 252142864.0000 - val_mse: 252142864.0000\n",
            "Epoch 168/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 176191960.7190 - mse: 176191960.7190 - val_loss: 351317792.0000 - val_mse: 351317792.0000\n",
            "Epoch 169/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 179514792.5490 - mse: 179514792.5490 - val_loss: 308033344.0000 - val_mse: 308033344.0000\n",
            "Epoch 170/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 166096788.8235 - mse: 166096788.8235 - val_loss: 247454848.0000 - val_mse: 247454848.0000\n",
            "Epoch 171/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 187800458.7190 - mse: 187800458.7190 - val_loss: 298761280.0000 - val_mse: 298761280.0000\n",
            "Epoch 172/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 171242697.7516 - mse: 171242697.7516 - val_loss: 287289152.0000 - val_mse: 287289152.0000\n",
            "Epoch 173/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 178879991.8431 - mse: 178879991.8431 - val_loss: 250575552.0000 - val_mse: 250575552.0000\n",
            "Epoch 174/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 174883420.6797 - mse: 174883420.6797 - val_loss: 275379552.0000 - val_mse: 275379552.0000\n",
            "Epoch 175/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 182404945.8431 - mse: 182404945.8431 - val_loss: 242694160.0000 - val_mse: 242694160.0000\n",
            "Epoch 176/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 163729021.4379 - mse: 163729021.4379 - val_loss: 352277312.0000 - val_mse: 352277312.0000\n",
            "Epoch 177/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 172539051.6078 - mse: 172539051.6078 - val_loss: 249245808.0000 - val_mse: 249245808.0000\n",
            "Epoch 178/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 168327854.4183 - mse: 168327854.4183 - val_loss: 256289856.0000 - val_mse: 256289856.0000\n",
            "Epoch 179/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 177606774.1176 - mse: 177606774.1176 - val_loss: 240194320.0000 - val_mse: 240194320.0000\n",
            "Epoch 180/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 174139906.5098 - mse: 174139906.5098 - val_loss: 290490912.0000 - val_mse: 290490912.0000\n",
            "Epoch 181/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 171366969.6471 - mse: 171366969.6471 - val_loss: 244126080.0000 - val_mse: 244126080.0000\n",
            "Epoch 182/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 168942237.3333 - mse: 168942237.3333 - val_loss: 311897728.0000 - val_mse: 311897728.0000\n",
            "Epoch 183/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 176944102.9542 - mse: 176944102.9542 - val_loss: 336127008.0000 - val_mse: 336127008.0000\n",
            "Epoch 184/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 169560613.6601 - mse: 169560613.6601 - val_loss: 324939456.0000 - val_mse: 324939456.0000\n",
            "Epoch 185/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 172366752.0915 - mse: 172366752.0915 - val_loss: 267485984.0000 - val_mse: 267485984.0000\n",
            "Epoch 186/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 172808026.2745 - mse: 172808026.2745 - val_loss: 234695376.0000 - val_mse: 234695376.0000\n",
            "Epoch 187/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 174290034.9542 - mse: 174290034.9542 - val_loss: 260423232.0000 - val_mse: 260423232.0000\n",
            "Epoch 188/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 172635798.4183 - mse: 172635798.4183 - val_loss: 401026848.0000 - val_mse: 401026848.0000\n",
            "Epoch 189/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 164875292.7582 - mse: 164875292.7582 - val_loss: 272148800.0000 - val_mse: 272148800.0000\n",
            "Epoch 190/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 172115158.1830 - mse: 172115158.1830 - val_loss: 272400096.0000 - val_mse: 272400096.0000\n",
            "Epoch 191/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 172453430.4837 - mse: 172453430.4837 - val_loss: 300608640.0000 - val_mse: 300608640.0000\n",
            "Epoch 192/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 163994409.6471 - mse: 163994409.6471 - val_loss: 258342672.0000 - val_mse: 258342672.0000\n",
            "Epoch 193/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 174410320.4183 - mse: 174410320.4183 - val_loss: 233244768.0000 - val_mse: 233244768.0000\n",
            "Epoch 194/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 174073496.7059 - mse: 174073496.7059 - val_loss: 385429760.0000 - val_mse: 385429760.0000\n",
            "Epoch 195/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 173401687.0458 - mse: 173401687.0458 - val_loss: 241103888.0000 - val_mse: 241103888.0000\n",
            "Epoch 196/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 171878124.9804 - mse: 171878124.9804 - val_loss: 307410144.0000 - val_mse: 307410144.0000\n",
            "Epoch 197/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 168055552.2876 - mse: 168055552.2876 - val_loss: 270215904.0000 - val_mse: 270215904.0000\n",
            "Epoch 198/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 169667709.9608 - mse: 169667709.9608 - val_loss: 262321664.0000 - val_mse: 262321664.0000\n",
            "Epoch 199/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 173015415.4248 - mse: 173015415.4248 - val_loss: 285043456.0000 - val_mse: 285043456.0000\n",
            "Epoch 200/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 173617400.0392 - mse: 173617400.0392 - val_loss: 263068272.0000 - val_mse: 263068272.0000\n",
            "Epoch 201/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 170667279.1111 - mse: 170667279.1111 - val_loss: 281067680.0000 - val_mse: 281067680.0000\n",
            "Epoch 202/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 166159525.7386 - mse: 166159525.7386 - val_loss: 258786256.0000 - val_mse: 258786256.0000\n",
            "Epoch 203/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 172031948.4444 - mse: 172031948.4444 - val_loss: 352378624.0000 - val_mse: 352378624.0000\n",
            "Epoch 204/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 170506141.6732 - mse: 170506141.6732 - val_loss: 342518400.0000 - val_mse: 342518400.0000\n",
            "Epoch 205/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 170677501.3856 - mse: 170677501.3856 - val_loss: 323801056.0000 - val_mse: 323801056.0000\n",
            "Epoch 206/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 173898640.4052 - mse: 173898640.4052 - val_loss: 318439072.0000 - val_mse: 318439072.0000\n",
            "Epoch 207/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 172370102.0131 - mse: 172370102.0131 - val_loss: 391604000.0000 - val_mse: 391604000.0000\n",
            "Epoch 208/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 174074703.0196 - mse: 174074703.0196 - val_loss: 306496736.0000 - val_mse: 306496736.0000\n",
            "Epoch 209/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 170113701.7778 - mse: 170113701.7778 - val_loss: 269435616.0000 - val_mse: 269435616.0000\n",
            "Epoch 210/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 170075363.9477 - mse: 170075363.9477 - val_loss: 257769296.0000 - val_mse: 257769296.0000\n",
            "Epoch 211/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 165340974.9542 - mse: 165340974.9542 - val_loss: 315040864.0000 - val_mse: 315040864.0000\n",
            "Epoch 212/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 168843647.9608 - mse: 168843647.9608 - val_loss: 329162144.0000 - val_mse: 329162144.0000\n",
            "Epoch 213/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 168919452.1176 - mse: 168919452.1176 - val_loss: 346721152.0000 - val_mse: 346721152.0000\n",
            "Epoch 214/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 172283144.1046 - mse: 172283144.1046 - val_loss: 311484736.0000 - val_mse: 311484736.0000\n",
            "Epoch 215/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 178790176.0523 - mse: 178790176.0523 - val_loss: 297177728.0000 - val_mse: 297177728.0000\n",
            "Epoch 216/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 163716603.6601 - mse: 163716603.6601 - val_loss: 317573440.0000 - val_mse: 317573440.0000\n",
            "Epoch 217/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 173714175.2418 - mse: 173714175.2418 - val_loss: 278960224.0000 - val_mse: 278960224.0000\n",
            "Epoch 218/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 174302020.9281 - mse: 174302020.9281 - val_loss: 263461008.0000 - val_mse: 263461008.0000\n",
            "Epoch 219/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 161845343.2026 - mse: 161845343.2026 - val_loss: 295928256.0000 - val_mse: 295928256.0000\n",
            "Epoch 220/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 168853879.9739 - mse: 168853879.9739 - val_loss: 265866496.0000 - val_mse: 265866496.0000\n",
            "Epoch 221/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 169465800.7582 - mse: 169465800.7582 - val_loss: 246673696.0000 - val_mse: 246673696.0000\n",
            "Epoch 222/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 173102296.5229 - mse: 173102296.5229 - val_loss: 289155968.0000 - val_mse: 289155968.0000\n",
            "Epoch 223/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 170691779.5294 - mse: 170691779.5294 - val_loss: 320898464.0000 - val_mse: 320898464.0000\n",
            "Epoch 224/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 172325031.8824 - mse: 172325031.8824 - val_loss: 297942976.0000 - val_mse: 297942976.0000\n",
            "Epoch 225/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 167413889.4379 - mse: 167413889.4379 - val_loss: 264081024.0000 - val_mse: 264081024.0000\n",
            "Epoch 226/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 167297258.6275 - mse: 167297258.6275 - val_loss: 234643008.0000 - val_mse: 234643008.0000\n",
            "Epoch 227/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 170728633.2026 - mse: 170728633.2026 - val_loss: 301996224.0000 - val_mse: 301996224.0000\n",
            "Epoch 228/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 168416188.8889 - mse: 168416188.8889 - val_loss: 279592640.0000 - val_mse: 279592640.0000\n",
            "Epoch 229/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 167210193.8301 - mse: 167210193.8301 - val_loss: 310462208.0000 - val_mse: 310462208.0000\n",
            "Epoch 230/300\n",
            "611/611 [==============================] - 4s 6ms/step - loss: 169742165.2549 - mse: 169742165.2549 - val_loss: 227781440.0000 - val_mse: 227781440.0000\n",
            "Epoch 231/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 167930030.1176 - mse: 167930030.1176 - val_loss: 236638480.0000 - val_mse: 236638480.0000\n",
            "Epoch 232/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 167882029.9869 - mse: 167882029.9869 - val_loss: 291140640.0000 - val_mse: 291140640.0000\n",
            "Epoch 233/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 170616800.4183 - mse: 170616800.4183 - val_loss: 249718848.0000 - val_mse: 249718848.0000\n",
            "Epoch 234/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 166733538.9020 - mse: 166733538.9020 - val_loss: 237695328.0000 - val_mse: 237695328.0000\n",
            "Epoch 235/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 163971339.0588 - mse: 163971339.0588 - val_loss: 331054816.0000 - val_mse: 331054816.0000\n",
            "Epoch 236/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 169130949.5425 - mse: 169130949.5425 - val_loss: 224638528.0000 - val_mse: 224638528.0000\n",
            "Epoch 237/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 168045503.9085 - mse: 168045503.9085 - val_loss: 295671744.0000 - val_mse: 295671744.0000\n",
            "Epoch 238/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 176207506.5359 - mse: 176207506.5359 - val_loss: 312407552.0000 - val_mse: 312407552.0000\n",
            "Epoch 239/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 166282963.0850 - mse: 166282963.0850 - val_loss: 225999696.0000 - val_mse: 225999696.0000\n",
            "Epoch 240/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 173002536.5229 - mse: 173002536.5229 - val_loss: 381945184.0000 - val_mse: 381945184.0000\n",
            "Epoch 241/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 167181899.2941 - mse: 167181899.2941 - val_loss: 234851648.0000 - val_mse: 234851648.0000\n",
            "Epoch 242/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 173207222.7451 - mse: 173207222.7451 - val_loss: 240757184.0000 - val_mse: 240757184.0000\n",
            "Epoch 243/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 170177502.0915 - mse: 170177502.0915 - val_loss: 332653152.0000 - val_mse: 332653152.0000\n",
            "Epoch 244/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 169309664.7059 - mse: 169309664.7059 - val_loss: 378413184.0000 - val_mse: 378413184.0000\n",
            "Epoch 245/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 171819464.0261 - mse: 171819464.0261 - val_loss: 343612704.0000 - val_mse: 343612704.0000\n",
            "Epoch 246/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 173904287.1765 - mse: 173904287.1765 - val_loss: 354071232.0000 - val_mse: 354071232.0000\n",
            "Epoch 247/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 172383775.8954 - mse: 172383775.8954 - val_loss: 225649008.0000 - val_mse: 225649008.0000\n",
            "Epoch 248/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 165394600.3922 - mse: 165394600.3922 - val_loss: 252356400.0000 - val_mse: 252356400.0000\n",
            "Epoch 249/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 166833427.3725 - mse: 166833427.3725 - val_loss: 326381952.0000 - val_mse: 326381952.0000\n",
            "Epoch 250/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 161569053.8301 - mse: 161569053.8301 - val_loss: 315404576.0000 - val_mse: 315404576.0000\n",
            "Epoch 251/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 162959721.0065 - mse: 162959721.0065 - val_loss: 315456480.0000 - val_mse: 315456480.0000\n",
            "Epoch 252/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 160387835.8562 - mse: 160387835.8562 - val_loss: 336598688.0000 - val_mse: 336598688.0000\n",
            "Epoch 253/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 168639486.9804 - mse: 168639486.9804 - val_loss: 231342160.0000 - val_mse: 231342160.0000\n",
            "Epoch 254/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 168647321.2549 - mse: 168647321.2549 - val_loss: 239719488.0000 - val_mse: 239719488.0000\n",
            "Epoch 255/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 171969730.0654 - mse: 171969730.0654 - val_loss: 233348896.0000 - val_mse: 233348896.0000\n",
            "Epoch 256/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 169144542.1699 - mse: 169144542.1699 - val_loss: 318434560.0000 - val_mse: 318434560.0000\n",
            "Epoch 257/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 162425677.4379 - mse: 162425677.4379 - val_loss: 363498176.0000 - val_mse: 363498176.0000\n",
            "Epoch 258/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 168374327.6863 - mse: 168374327.6863 - val_loss: 294316320.0000 - val_mse: 294316320.0000\n",
            "Epoch 259/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 163727761.8301 - mse: 163727761.8301 - val_loss: 410596320.0000 - val_mse: 410596320.0000\n",
            "Epoch 260/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 168767219.9739 - mse: 168767219.9739 - val_loss: 285102912.0000 - val_mse: 285102912.0000\n",
            "Epoch 261/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 166611439.9216 - mse: 166611439.9216 - val_loss: 342212800.0000 - val_mse: 342212800.0000\n",
            "Epoch 262/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 164398134.2222 - mse: 164398134.2222 - val_loss: 235710544.0000 - val_mse: 235710544.0000\n",
            "Epoch 263/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 172350008.9935 - mse: 172350008.9935 - val_loss: 285407200.0000 - val_mse: 285407200.0000\n",
            "Epoch 264/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 165702724.5621 - mse: 165702724.5621 - val_loss: 232159344.0000 - val_mse: 232159344.0000\n",
            "Epoch 265/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 165301044.9935 - mse: 165301044.9935 - val_loss: 413745184.0000 - val_mse: 413745184.0000\n",
            "Epoch 266/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 169051444.1307 - mse: 169051444.1307 - val_loss: 352467296.0000 - val_mse: 352467296.0000\n",
            "Epoch 267/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 171593803.1634 - mse: 171593803.1634 - val_loss: 422499072.0000 - val_mse: 422499072.0000\n",
            "Epoch 268/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 157879829.4118 - mse: 157879829.4118 - val_loss: 241625072.0000 - val_mse: 241625072.0000\n",
            "Epoch 269/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 163568772.3007 - mse: 163568772.3007 - val_loss: 265738640.0000 - val_mse: 265738640.0000\n",
            "Epoch 270/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 169502510.3007 - mse: 169502510.3007 - val_loss: 443831936.0000 - val_mse: 443831936.0000\n",
            "Epoch 271/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 168849731.5425 - mse: 168849731.5425 - val_loss: 221782144.0000 - val_mse: 221782144.0000\n",
            "Epoch 272/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 161989442.4052 - mse: 161989442.4052 - val_loss: 277011616.0000 - val_mse: 277011616.0000\n",
            "Epoch 273/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 163648037.2288 - mse: 163648037.2288 - val_loss: 293454368.0000 - val_mse: 293454368.0000\n",
            "Epoch 274/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 168358395.2288 - mse: 168358395.2288 - val_loss: 250724400.0000 - val_mse: 250724400.0000\n",
            "Epoch 275/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 165007821.7516 - mse: 165007821.7516 - val_loss: 228451184.0000 - val_mse: 228451184.0000\n",
            "Epoch 276/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 165472871.7778 - mse: 165472871.7778 - val_loss: 242029600.0000 - val_mse: 242029600.0000\n",
            "Epoch 277/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 168999008.1699 - mse: 168999008.1699 - val_loss: 253456016.0000 - val_mse: 253456016.0000\n",
            "Epoch 278/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 168353073.8039 - mse: 168353073.8039 - val_loss: 253146704.0000 - val_mse: 253146704.0000\n",
            "Epoch 279/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 170860466.7190 - mse: 170860466.7190 - val_loss: 290992192.0000 - val_mse: 290992192.0000\n",
            "Epoch 280/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 167161951.5425 - mse: 167161951.5425 - val_loss: 224134992.0000 - val_mse: 224134992.0000\n",
            "Epoch 281/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 166944978.9020 - mse: 166944978.9020 - val_loss: 345162272.0000 - val_mse: 345162272.0000\n",
            "Epoch 282/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 161740927.9477 - mse: 161740927.9477 - val_loss: 274608672.0000 - val_mse: 274608672.0000\n",
            "Epoch 283/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 175726768.1830 - mse: 175726768.1830 - val_loss: 295001280.0000 - val_mse: 295001280.0000\n",
            "Epoch 284/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 169244956.8105 - mse: 169244956.8105 - val_loss: 289783424.0000 - val_mse: 289783424.0000\n",
            "Epoch 285/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 167126695.9739 - mse: 167126695.9739 - val_loss: 285520384.0000 - val_mse: 285520384.0000\n",
            "Epoch 286/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 167328091.8954 - mse: 167328091.8954 - val_loss: 271895744.0000 - val_mse: 271895744.0000\n",
            "Epoch 287/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 158710601.7647 - mse: 158710601.7647 - val_loss: 273434784.0000 - val_mse: 273434784.0000\n",
            "Epoch 288/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 163655022.9281 - mse: 163655022.9281 - val_loss: 257798176.0000 - val_mse: 257798176.0000\n",
            "Epoch 289/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 163438842.5098 - mse: 163438842.5098 - val_loss: 283928384.0000 - val_mse: 283928384.0000\n",
            "Epoch 290/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 158935635.5294 - mse: 158935635.5294 - val_loss: 257143680.0000 - val_mse: 257143680.0000\n",
            "Epoch 291/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 159276643.9608 - mse: 159276643.9608 - val_loss: 352429696.0000 - val_mse: 352429696.0000\n",
            "Epoch 292/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 172883322.1961 - mse: 172883322.1961 - val_loss: 221487936.0000 - val_mse: 221487936.0000\n",
            "Epoch 293/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 164087740.7843 - mse: 164087740.7843 - val_loss: 219930080.0000 - val_mse: 219930080.0000\n",
            "Epoch 294/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 164705091.7647 - mse: 164705091.7647 - val_loss: 272564128.0000 - val_mse: 272564128.0000\n",
            "Epoch 295/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 167778667.3725 - mse: 167778667.3725 - val_loss: 315060896.0000 - val_mse: 315060896.0000\n",
            "Epoch 296/300\n",
            "611/611 [==============================] - 3s 5ms/step - loss: 168619446.9020 - mse: 168619446.9020 - val_loss: 230760512.0000 - val_mse: 230760512.0000\n",
            "Epoch 297/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 164549035.3464 - mse: 164549035.3464 - val_loss: 266194832.0000 - val_mse: 266194832.0000\n",
            "Epoch 298/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 160502611.6863 - mse: 160502611.6863 - val_loss: 247213808.0000 - val_mse: 247213808.0000\n",
            "Epoch 299/300\n",
            "611/611 [==============================] - 3s 6ms/step - loss: 163523472.1569 - mse: 163523472.1569 - val_loss: 371966848.0000 - val_mse: 371966848.0000\n",
            "Epoch 300/300\n",
            "611/611 [==============================] - 4s 6ms/step - loss: 160694195.5425 - mse: 160694195.5425 - val_loss: 338236032.0000 - val_mse: 338236032.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntt3TXtP1Ec-"
      },
      "source": [
        "### 2.3 어떤문제가 발생했는지 설명해주세요.\n",
        "\n",
        "- validation mse가 338236032.0000가 lgbm보다 크다\n",
        "test loss가 들쭉날쭉하다.\n",
        "val_loss: 338236032.0000\n",
        "\n",
        "힌트\n",
        "\n",
        "- 이전에 lgbm 같은 경우 validation mse가 $1.2 * 10^8$ 이였습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqklrdd81Ec-"
      },
      "source": [
        "### 2.4 더 좋은 성능의 딥러닝 모델을 위해\n",
        "\n",
        "- test set에 대해 딥러닝 모형의 성능을 평가하세요.\n",
        "- dense 조절, batch_size 조절, regularization, dropout, batch normalization 등의 방법을 활용해 최고의 성능을 얻어보세요.\n",
        "- 만약 성능의 향상이 어렵다면, 다양한 방법들을 시도하는 것을 목표로 해주세요!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cycv81ZR1Ec_"
      },
      "source": [
        "feature_list = list(train_x.columns)\n",
        "\n",
        "CBE_encoder = CatBoostEncoder()\n",
        "train_cbe = CBE_encoder.fit_transform(train_x[feature_list], train_y)\n",
        "test_cbe = CBE_encoder.transform(test_x[feature_list])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMuGM6T5C_gy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uFqLx8e8r2g",
        "outputId": "6075e584-8068-4f27-930c-862862a93d1a"
      },
      "source": [
        "history = model.fit(train_tune_cbe, train_tune_y, epochs=300, validation_data = (val_cbe, val_y), batch_size = 256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 164374752.0000 - mse: 164374752.0000 - val_loss: 225515248.0000 - val_mse: 225515248.0000\n",
            "Epoch 2/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 164386784.0000 - mse: 164386784.0000 - val_loss: 312315296.0000 - val_mse: 312315296.0000\n",
            "Epoch 3/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 164169504.0000 - mse: 164169504.0000 - val_loss: 307400096.0000 - val_mse: 307400096.0000\n",
            "Epoch 4/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 163931248.0000 - mse: 163931248.0000 - val_loss: 315521408.0000 - val_mse: 315521408.0000\n",
            "Epoch 5/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 163961984.0000 - mse: 163961984.0000 - val_loss: 260689984.0000 - val_mse: 260689984.0000\n",
            "Epoch 6/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 163538320.0000 - mse: 163538320.0000 - val_loss: 237708784.0000 - val_mse: 237708784.0000\n",
            "Epoch 7/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 163313264.0000 - mse: 163313264.0000 - val_loss: 266204080.0000 - val_mse: 266204080.0000\n",
            "Epoch 8/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 163013744.0000 - mse: 163013744.0000 - val_loss: 249166208.0000 - val_mse: 249166208.0000\n",
            "Epoch 9/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 163513792.0000 - mse: 163513792.0000 - val_loss: 284015552.0000 - val_mse: 284015552.0000\n",
            "Epoch 10/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 163133856.0000 - mse: 163133856.0000 - val_loss: 263046576.0000 - val_mse: 263046576.0000\n",
            "Epoch 11/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 162988208.0000 - mse: 162988208.0000 - val_loss: 245449616.0000 - val_mse: 245449616.0000\n",
            "Epoch 12/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 162813392.0000 - mse: 162813392.0000 - val_loss: 263249312.0000 - val_mse: 263249312.0000\n",
            "Epoch 13/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 163019536.0000 - mse: 163019536.0000 - val_loss: 358235808.0000 - val_mse: 358235808.0000\n",
            "Epoch 14/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 163138320.0000 - mse: 163138320.0000 - val_loss: 299975424.0000 - val_mse: 299975424.0000\n",
            "Epoch 15/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 162651888.0000 - mse: 162651888.0000 - val_loss: 284185216.0000 - val_mse: 284185216.0000\n",
            "Epoch 16/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 162326736.0000 - mse: 162326736.0000 - val_loss: 264596912.0000 - val_mse: 264596912.0000\n",
            "Epoch 17/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 162100736.0000 - mse: 162100736.0000 - val_loss: 361798784.0000 - val_mse: 361798784.0000\n",
            "Epoch 18/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 161742080.0000 - mse: 161742080.0000 - val_loss: 292758976.0000 - val_mse: 292758976.0000\n",
            "Epoch 19/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 162121984.0000 - mse: 162121984.0000 - val_loss: 325988096.0000 - val_mse: 325988096.0000\n",
            "Epoch 20/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 161973984.0000 - mse: 161973984.0000 - val_loss: 261015392.0000 - val_mse: 261015392.0000\n",
            "Epoch 21/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 161729376.0000 - mse: 161729376.0000 - val_loss: 302533280.0000 - val_mse: 302533280.0000\n",
            "Epoch 22/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 161653280.0000 - mse: 161653280.0000 - val_loss: 274945440.0000 - val_mse: 274945440.0000\n",
            "Epoch 23/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 161664608.0000 - mse: 161664608.0000 - val_loss: 268882240.0000 - val_mse: 268882240.0000\n",
            "Epoch 24/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 161604768.0000 - mse: 161604768.0000 - val_loss: 217793536.0000 - val_mse: 217793536.0000\n",
            "Epoch 25/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 161388768.0000 - mse: 161388768.0000 - val_loss: 336058272.0000 - val_mse: 336058272.0000\n",
            "Epoch 26/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 161020160.0000 - mse: 161020160.0000 - val_loss: 280763968.0000 - val_mse: 280763968.0000\n",
            "Epoch 27/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 161095760.0000 - mse: 161095760.0000 - val_loss: 223612384.0000 - val_mse: 223612384.0000\n",
            "Epoch 28/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 161013648.0000 - mse: 161013648.0000 - val_loss: 273359648.0000 - val_mse: 273359648.0000\n",
            "Epoch 29/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 160931984.0000 - mse: 160931984.0000 - val_loss: 218100176.0000 - val_mse: 218100176.0000\n",
            "Epoch 30/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 160705600.0000 - mse: 160705600.0000 - val_loss: 248721712.0000 - val_mse: 248721712.0000\n",
            "Epoch 31/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 160485216.0000 - mse: 160485216.0000 - val_loss: 330473120.0000 - val_mse: 330473120.0000\n",
            "Epoch 32/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 160473728.0000 - mse: 160473728.0000 - val_loss: 288961312.0000 - val_mse: 288961312.0000\n",
            "Epoch 33/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 160486000.0000 - mse: 160486000.0000 - val_loss: 313258752.0000 - val_mse: 313258752.0000\n",
            "Epoch 34/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 160247456.0000 - mse: 160247456.0000 - val_loss: 225603456.0000 - val_mse: 225603456.0000\n",
            "Epoch 35/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 159964384.0000 - mse: 159964384.0000 - val_loss: 257403856.0000 - val_mse: 257403856.0000\n",
            "Epoch 36/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 159889888.0000 - mse: 159889888.0000 - val_loss: 271850976.0000 - val_mse: 271850976.0000\n",
            "Epoch 37/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 160318656.0000 - mse: 160318656.0000 - val_loss: 283993632.0000 - val_mse: 283993632.0000\n",
            "Epoch 38/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 159828768.0000 - mse: 159828768.0000 - val_loss: 243057792.0000 - val_mse: 243057792.0000\n",
            "Epoch 39/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 159677696.0000 - mse: 159677696.0000 - val_loss: 373513760.0000 - val_mse: 373513760.0000\n",
            "Epoch 40/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 159993616.0000 - mse: 159993616.0000 - val_loss: 261788608.0000 - val_mse: 261788608.0000\n",
            "Epoch 41/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 159502224.0000 - mse: 159502224.0000 - val_loss: 264055616.0000 - val_mse: 264055616.0000\n",
            "Epoch 42/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 159746560.0000 - mse: 159746560.0000 - val_loss: 212064288.0000 - val_mse: 212064288.0000\n",
            "Epoch 43/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 159259344.0000 - mse: 159259344.0000 - val_loss: 235668320.0000 - val_mse: 235668320.0000\n",
            "Epoch 44/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 159132016.0000 - mse: 159132016.0000 - val_loss: 259601696.0000 - val_mse: 259601696.0000\n",
            "Epoch 45/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 159142080.0000 - mse: 159142080.0000 - val_loss: 236859232.0000 - val_mse: 236859232.0000\n",
            "Epoch 46/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 158778000.0000 - mse: 158778000.0000 - val_loss: 264225440.0000 - val_mse: 264225440.0000\n",
            "Epoch 47/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 158968448.0000 - mse: 158968448.0000 - val_loss: 251182848.0000 - val_mse: 251182848.0000\n",
            "Epoch 48/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 158915808.0000 - mse: 158915808.0000 - val_loss: 316506144.0000 - val_mse: 316506144.0000\n",
            "Epoch 49/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 158666304.0000 - mse: 158666304.0000 - val_loss: 322283648.0000 - val_mse: 322283648.0000\n",
            "Epoch 50/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 158764800.0000 - mse: 158764800.0000 - val_loss: 286050912.0000 - val_mse: 286050912.0000\n",
            "Epoch 51/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 158096384.0000 - mse: 158096384.0000 - val_loss: 372939872.0000 - val_mse: 372939872.0000\n",
            "Epoch 52/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 158000480.0000 - mse: 158000480.0000 - val_loss: 357157312.0000 - val_mse: 357157312.0000\n",
            "Epoch 53/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 157868416.0000 - mse: 157868416.0000 - val_loss: 307747264.0000 - val_mse: 307747264.0000\n",
            "Epoch 54/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 157456848.0000 - mse: 157456848.0000 - val_loss: 302850528.0000 - val_mse: 302850528.0000\n",
            "Epoch 55/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 157567456.0000 - mse: 157567456.0000 - val_loss: 355042240.0000 - val_mse: 355042240.0000\n",
            "Epoch 56/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 157487232.0000 - mse: 157487232.0000 - val_loss: 328801056.0000 - val_mse: 328801056.0000\n",
            "Epoch 57/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 156717840.0000 - mse: 156717840.0000 - val_loss: 289595040.0000 - val_mse: 289595040.0000\n",
            "Epoch 58/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 156890928.0000 - mse: 156890928.0000 - val_loss: 260535696.0000 - val_mse: 260535696.0000\n",
            "Epoch 59/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 157198640.0000 - mse: 157198640.0000 - val_loss: 287602880.0000 - val_mse: 287602880.0000\n",
            "Epoch 60/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 156747968.0000 - mse: 156747968.0000 - val_loss: 284960640.0000 - val_mse: 284960640.0000\n",
            "Epoch 61/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 157179600.0000 - mse: 157179600.0000 - val_loss: 226933808.0000 - val_mse: 226933808.0000\n",
            "Epoch 62/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 156798928.0000 - mse: 156798928.0000 - val_loss: 245821392.0000 - val_mse: 245821392.0000\n",
            "Epoch 63/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 156978480.0000 - mse: 156978480.0000 - val_loss: 452055232.0000 - val_mse: 452055232.0000\n",
            "Epoch 64/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 156616992.0000 - mse: 156616992.0000 - val_loss: 269559872.0000 - val_mse: 269559872.0000\n",
            "Epoch 65/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 156676448.0000 - mse: 156676448.0000 - val_loss: 243294480.0000 - val_mse: 243294480.0000\n",
            "Epoch 66/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 156367120.0000 - mse: 156367120.0000 - val_loss: 279005088.0000 - val_mse: 279005088.0000\n",
            "Epoch 67/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 156239200.0000 - mse: 156239200.0000 - val_loss: 236756944.0000 - val_mse: 236756944.0000\n",
            "Epoch 68/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 156419072.0000 - mse: 156419072.0000 - val_loss: 303700352.0000 - val_mse: 303700352.0000\n",
            "Epoch 69/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 155809536.0000 - mse: 155809536.0000 - val_loss: 301679680.0000 - val_mse: 301679680.0000\n",
            "Epoch 70/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 155727840.0000 - mse: 155727840.0000 - val_loss: 336229984.0000 - val_mse: 336229984.0000\n",
            "Epoch 71/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 155866496.0000 - mse: 155866496.0000 - val_loss: 247984640.0000 - val_mse: 247984640.0000\n",
            "Epoch 72/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 155497584.0000 - mse: 155497584.0000 - val_loss: 226756368.0000 - val_mse: 226756368.0000\n",
            "Epoch 73/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 155593728.0000 - mse: 155593728.0000 - val_loss: 266831600.0000 - val_mse: 266831600.0000\n",
            "Epoch 74/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 155092800.0000 - mse: 155092800.0000 - val_loss: 267661328.0000 - val_mse: 267661328.0000\n",
            "Epoch 75/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 155206928.0000 - mse: 155206928.0000 - val_loss: 465055328.0000 - val_mse: 465055328.0000\n",
            "Epoch 76/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 155153232.0000 - mse: 155153232.0000 - val_loss: 292232576.0000 - val_mse: 292232576.0000\n",
            "Epoch 77/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 154875792.0000 - mse: 154875792.0000 - val_loss: 300980480.0000 - val_mse: 300980480.0000\n",
            "Epoch 78/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 154740576.0000 - mse: 154740576.0000 - val_loss: 220439152.0000 - val_mse: 220439152.0000\n",
            "Epoch 79/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 154875392.0000 - mse: 154875392.0000 - val_loss: 247243232.0000 - val_mse: 247243232.0000\n",
            "Epoch 80/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 155161120.0000 - mse: 155161120.0000 - val_loss: 333621696.0000 - val_mse: 333621696.0000\n",
            "Epoch 81/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 154563120.0000 - mse: 154563120.0000 - val_loss: 283343136.0000 - val_mse: 283343136.0000\n",
            "Epoch 82/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 154115328.0000 - mse: 154115328.0000 - val_loss: 253853984.0000 - val_mse: 253853984.0000\n",
            "Epoch 83/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 154273616.0000 - mse: 154273616.0000 - val_loss: 241995376.0000 - val_mse: 241995376.0000\n",
            "Epoch 84/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 154239168.0000 - mse: 154239168.0000 - val_loss: 232628416.0000 - val_mse: 232628416.0000\n",
            "Epoch 85/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 154431824.0000 - mse: 154431824.0000 - val_loss: 200054544.0000 - val_mse: 200054544.0000\n",
            "Epoch 86/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 153385136.0000 - mse: 153385136.0000 - val_loss: 314538208.0000 - val_mse: 314538208.0000\n",
            "Epoch 87/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 153445312.0000 - mse: 153445312.0000 - val_loss: 269240832.0000 - val_mse: 269240832.0000\n",
            "Epoch 88/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 153863120.0000 - mse: 153863120.0000 - val_loss: 305208576.0000 - val_mse: 305208576.0000\n",
            "Epoch 89/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 153610880.0000 - mse: 153610880.0000 - val_loss: 219350784.0000 - val_mse: 219350784.0000\n",
            "Epoch 90/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 153276112.0000 - mse: 153276112.0000 - val_loss: 203344368.0000 - val_mse: 203344368.0000\n",
            "Epoch 91/300\n",
            "1221/1221 [==============================] - 4s 3ms/step - loss: 153249600.0000 - mse: 153249600.0000 - val_loss: 332644832.0000 - val_mse: 332644832.0000\n",
            "Epoch 92/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 153296496.0000 - mse: 153296496.0000 - val_loss: 285187104.0000 - val_mse: 285187104.0000\n",
            "Epoch 93/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 153315296.0000 - mse: 153315296.0000 - val_loss: 215949088.0000 - val_mse: 215949088.0000\n",
            "Epoch 94/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 153380944.0000 - mse: 153380944.0000 - val_loss: 270838496.0000 - val_mse: 270838496.0000\n",
            "Epoch 95/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 152613968.0000 - mse: 152613968.0000 - val_loss: 327285696.0000 - val_mse: 327285696.0000\n",
            "Epoch 96/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 152889904.0000 - mse: 152889904.0000 - val_loss: 285467424.0000 - val_mse: 285467424.0000\n",
            "Epoch 97/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 152520576.0000 - mse: 152520576.0000 - val_loss: 295386912.0000 - val_mse: 295386912.0000\n",
            "Epoch 98/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 152668240.0000 - mse: 152668240.0000 - val_loss: 208221312.0000 - val_mse: 208221312.0000\n",
            "Epoch 99/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 152205104.0000 - mse: 152205104.0000 - val_loss: 238604544.0000 - val_mse: 238604544.0000\n",
            "Epoch 100/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 152465120.0000 - mse: 152465120.0000 - val_loss: 354707296.0000 - val_mse: 354707296.0000\n",
            "Epoch 101/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 152214544.0000 - mse: 152214544.0000 - val_loss: 280928384.0000 - val_mse: 280928384.0000\n",
            "Epoch 102/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 152211552.0000 - mse: 152211552.0000 - val_loss: 257295760.0000 - val_mse: 257295760.0000\n",
            "Epoch 103/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 151855280.0000 - mse: 151855280.0000 - val_loss: 316824032.0000 - val_mse: 316824032.0000\n",
            "Epoch 104/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 152652064.0000 - mse: 152652064.0000 - val_loss: 285948576.0000 - val_mse: 285948576.0000\n",
            "Epoch 105/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 152428816.0000 - mse: 152428816.0000 - val_loss: 219433456.0000 - val_mse: 219433456.0000\n",
            "Epoch 106/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 151836144.0000 - mse: 151836144.0000 - val_loss: 266883440.0000 - val_mse: 266883440.0000\n",
            "Epoch 107/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 152040832.0000 - mse: 152040832.0000 - val_loss: 288916672.0000 - val_mse: 288916672.0000\n",
            "Epoch 108/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 151955792.0000 - mse: 151955792.0000 - val_loss: 296487808.0000 - val_mse: 296487808.0000\n",
            "Epoch 109/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 152439600.0000 - mse: 152439600.0000 - val_loss: 222971456.0000 - val_mse: 222971456.0000\n",
            "Epoch 110/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 152068768.0000 - mse: 152068768.0000 - val_loss: 318998144.0000 - val_mse: 318998144.0000\n",
            "Epoch 111/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 151365984.0000 - mse: 151365984.0000 - val_loss: 241057920.0000 - val_mse: 241057920.0000\n",
            "Epoch 112/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 152123664.0000 - mse: 152123664.0000 - val_loss: 310048352.0000 - val_mse: 310048352.0000\n",
            "Epoch 113/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 150985568.0000 - mse: 150985568.0000 - val_loss: 195629728.0000 - val_mse: 195629728.0000\n",
            "Epoch 114/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 151314384.0000 - mse: 151314384.0000 - val_loss: 268631616.0000 - val_mse: 268631616.0000\n",
            "Epoch 115/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 151737344.0000 - mse: 151737344.0000 - val_loss: 191757600.0000 - val_mse: 191757600.0000\n",
            "Epoch 116/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 151265536.0000 - mse: 151265536.0000 - val_loss: 290108992.0000 - val_mse: 290108992.0000\n",
            "Epoch 117/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 151064560.0000 - mse: 151064560.0000 - val_loss: 205251232.0000 - val_mse: 205251232.0000\n",
            "Epoch 118/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 151359344.0000 - mse: 151359344.0000 - val_loss: 244010048.0000 - val_mse: 244010048.0000\n",
            "Epoch 119/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 150998416.0000 - mse: 150998416.0000 - val_loss: 295450208.0000 - val_mse: 295450208.0000\n",
            "Epoch 120/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 151062224.0000 - mse: 151062224.0000 - val_loss: 218857568.0000 - val_mse: 218857568.0000\n",
            "Epoch 121/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 151054336.0000 - mse: 151054336.0000 - val_loss: 298050144.0000 - val_mse: 298050144.0000\n",
            "Epoch 122/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 151214528.0000 - mse: 151214528.0000 - val_loss: 208794592.0000 - val_mse: 208794592.0000\n",
            "Epoch 123/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 150880944.0000 - mse: 150880944.0000 - val_loss: 250503200.0000 - val_mse: 250503200.0000\n",
            "Epoch 124/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 151057376.0000 - mse: 151057376.0000 - val_loss: 203419200.0000 - val_mse: 203419200.0000\n",
            "Epoch 125/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 150456880.0000 - mse: 150456880.0000 - val_loss: 254647648.0000 - val_mse: 254647648.0000\n",
            "Epoch 126/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 150214448.0000 - mse: 150214448.0000 - val_loss: 260102848.0000 - val_mse: 260102848.0000\n",
            "Epoch 127/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 151076912.0000 - mse: 151076912.0000 - val_loss: 282347264.0000 - val_mse: 282347264.0000\n",
            "Epoch 128/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 150307328.0000 - mse: 150307328.0000 - val_loss: 283117248.0000 - val_mse: 283117248.0000\n",
            "Epoch 129/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 150225952.0000 - mse: 150225952.0000 - val_loss: 259200864.0000 - val_mse: 259200864.0000\n",
            "Epoch 130/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 150052320.0000 - mse: 150052320.0000 - val_loss: 219865984.0000 - val_mse: 219865984.0000\n",
            "Epoch 131/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149867104.0000 - mse: 149867104.0000 - val_loss: 191511056.0000 - val_mse: 191511056.0000\n",
            "Epoch 132/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 150606624.0000 - mse: 150606624.0000 - val_loss: 240106624.0000 - val_mse: 240106624.0000\n",
            "Epoch 133/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 150213280.0000 - mse: 150213280.0000 - val_loss: 316460512.0000 - val_mse: 316460512.0000\n",
            "Epoch 134/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 150400528.0000 - mse: 150400528.0000 - val_loss: 222159008.0000 - val_mse: 222159008.0000\n",
            "Epoch 135/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149740944.0000 - mse: 149740944.0000 - val_loss: 343833088.0000 - val_mse: 343833088.0000\n",
            "Epoch 136/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149435568.0000 - mse: 149435568.0000 - val_loss: 190162080.0000 - val_mse: 190162080.0000\n",
            "Epoch 137/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149990848.0000 - mse: 149990848.0000 - val_loss: 360082048.0000 - val_mse: 360082048.0000\n",
            "Epoch 138/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 150129728.0000 - mse: 150129728.0000 - val_loss: 244710080.0000 - val_mse: 244710080.0000\n",
            "Epoch 139/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149569120.0000 - mse: 149569120.0000 - val_loss: 271358432.0000 - val_mse: 271358432.0000\n",
            "Epoch 140/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149565808.0000 - mse: 149565808.0000 - val_loss: 209052496.0000 - val_mse: 209052496.0000\n",
            "Epoch 141/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 150057056.0000 - mse: 150057056.0000 - val_loss: 191131360.0000 - val_mse: 191131360.0000\n",
            "Epoch 142/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149762384.0000 - mse: 149762384.0000 - val_loss: 188603984.0000 - val_mse: 188603984.0000\n",
            "Epoch 143/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149683360.0000 - mse: 149683360.0000 - val_loss: 203493600.0000 - val_mse: 203493600.0000\n",
            "Epoch 144/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149395344.0000 - mse: 149395344.0000 - val_loss: 188394208.0000 - val_mse: 188394208.0000\n",
            "Epoch 145/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149563296.0000 - mse: 149563296.0000 - val_loss: 238875680.0000 - val_mse: 238875680.0000\n",
            "Epoch 146/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149472736.0000 - mse: 149472736.0000 - val_loss: 230929152.0000 - val_mse: 230929152.0000\n",
            "Epoch 147/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149508320.0000 - mse: 149508320.0000 - val_loss: 275740640.0000 - val_mse: 275740640.0000\n",
            "Epoch 148/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 148819360.0000 - mse: 148819360.0000 - val_loss: 254484560.0000 - val_mse: 254484560.0000\n",
            "Epoch 149/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149400768.0000 - mse: 149400768.0000 - val_loss: 284707104.0000 - val_mse: 284707104.0000\n",
            "Epoch 150/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149443024.0000 - mse: 149443024.0000 - val_loss: 193024976.0000 - val_mse: 193024976.0000\n",
            "Epoch 151/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149756656.0000 - mse: 149756656.0000 - val_loss: 237024480.0000 - val_mse: 237024480.0000\n",
            "Epoch 152/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149186544.0000 - mse: 149186544.0000 - val_loss: 324306368.0000 - val_mse: 324306368.0000\n",
            "Epoch 153/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149626848.0000 - mse: 149626848.0000 - val_loss: 288175456.0000 - val_mse: 288175456.0000\n",
            "Epoch 154/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 148696400.0000 - mse: 148696400.0000 - val_loss: 315930048.0000 - val_mse: 315930048.0000\n",
            "Epoch 155/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 148028448.0000 - mse: 148028448.0000 - val_loss: 199069088.0000 - val_mse: 199069088.0000\n",
            "Epoch 156/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 148841936.0000 - mse: 148841936.0000 - val_loss: 183811040.0000 - val_mse: 183811040.0000\n",
            "Epoch 157/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149330784.0000 - mse: 149330784.0000 - val_loss: 217720080.0000 - val_mse: 217720080.0000\n",
            "Epoch 158/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147948208.0000 - mse: 147948208.0000 - val_loss: 239355680.0000 - val_mse: 239355680.0000\n",
            "Epoch 159/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 149085088.0000 - mse: 149085088.0000 - val_loss: 224538576.0000 - val_mse: 224538576.0000\n",
            "Epoch 160/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 148658448.0000 - mse: 148658448.0000 - val_loss: 272885792.0000 - val_mse: 272885792.0000\n",
            "Epoch 161/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 148811872.0000 - mse: 148811872.0000 - val_loss: 395801632.0000 - val_mse: 395801632.0000\n",
            "Epoch 162/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 148347584.0000 - mse: 148347584.0000 - val_loss: 345643936.0000 - val_mse: 345643936.0000\n",
            "Epoch 163/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 148604128.0000 - mse: 148604128.0000 - val_loss: 322094240.0000 - val_mse: 322094240.0000\n",
            "Epoch 164/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 148240464.0000 - mse: 148240464.0000 - val_loss: 360577504.0000 - val_mse: 360577504.0000\n",
            "Epoch 165/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 148102832.0000 - mse: 148102832.0000 - val_loss: 336541600.0000 - val_mse: 336541600.0000\n",
            "Epoch 166/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147789840.0000 - mse: 147789840.0000 - val_loss: 232202208.0000 - val_mse: 232202208.0000\n",
            "Epoch 167/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 148050832.0000 - mse: 148050832.0000 - val_loss: 266348192.0000 - val_mse: 266348192.0000\n",
            "Epoch 168/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 148283344.0000 - mse: 148283344.0000 - val_loss: 225533264.0000 - val_mse: 225533264.0000\n",
            "Epoch 169/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 148273888.0000 - mse: 148273888.0000 - val_loss: 257545824.0000 - val_mse: 257545824.0000\n",
            "Epoch 170/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 148737968.0000 - mse: 148737968.0000 - val_loss: 301180096.0000 - val_mse: 301180096.0000\n",
            "Epoch 171/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147876608.0000 - mse: 147876608.0000 - val_loss: 351273472.0000 - val_mse: 351273472.0000\n",
            "Epoch 172/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 148008272.0000 - mse: 148008272.0000 - val_loss: 196510704.0000 - val_mse: 196510704.0000\n",
            "Epoch 173/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 148026688.0000 - mse: 148026688.0000 - val_loss: 199266560.0000 - val_mse: 199266560.0000\n",
            "Epoch 174/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147566368.0000 - mse: 147566368.0000 - val_loss: 265631296.0000 - val_mse: 265631296.0000\n",
            "Epoch 175/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147755200.0000 - mse: 147755200.0000 - val_loss: 260558096.0000 - val_mse: 260558096.0000\n",
            "Epoch 176/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146755040.0000 - mse: 146755040.0000 - val_loss: 305838848.0000 - val_mse: 305838848.0000\n",
            "Epoch 177/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147459712.0000 - mse: 147459712.0000 - val_loss: 182854688.0000 - val_mse: 182854688.0000\n",
            "Epoch 178/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147310192.0000 - mse: 147310192.0000 - val_loss: 188956368.0000 - val_mse: 188956368.0000\n",
            "Epoch 179/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146047792.0000 - mse: 146047792.0000 - val_loss: 202799952.0000 - val_mse: 202799952.0000\n",
            "Epoch 180/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147579488.0000 - mse: 147579488.0000 - val_loss: 190596752.0000 - val_mse: 190596752.0000\n",
            "Epoch 181/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147326928.0000 - mse: 147326928.0000 - val_loss: 321323872.0000 - val_mse: 321323872.0000\n",
            "Epoch 182/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147521648.0000 - mse: 147521648.0000 - val_loss: 337897376.0000 - val_mse: 337897376.0000\n",
            "Epoch 183/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147382208.0000 - mse: 147382208.0000 - val_loss: 187177152.0000 - val_mse: 187177152.0000\n",
            "Epoch 184/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147346432.0000 - mse: 147346432.0000 - val_loss: 331557856.0000 - val_mse: 331557856.0000\n",
            "Epoch 185/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147251232.0000 - mse: 147251232.0000 - val_loss: 306493856.0000 - val_mse: 306493856.0000\n",
            "Epoch 186/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147173648.0000 - mse: 147173648.0000 - val_loss: 300166016.0000 - val_mse: 300166016.0000\n",
            "Epoch 187/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147114192.0000 - mse: 147114192.0000 - val_loss: 309721344.0000 - val_mse: 309721344.0000\n",
            "Epoch 188/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147259536.0000 - mse: 147259536.0000 - val_loss: 357467360.0000 - val_mse: 357467360.0000\n",
            "Epoch 189/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146941024.0000 - mse: 146941024.0000 - val_loss: 317032800.0000 - val_mse: 317032800.0000\n",
            "Epoch 190/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146872064.0000 - mse: 146872064.0000 - val_loss: 283108480.0000 - val_mse: 283108480.0000\n",
            "Epoch 191/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147168576.0000 - mse: 147168576.0000 - val_loss: 221264512.0000 - val_mse: 221264512.0000\n",
            "Epoch 192/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146913600.0000 - mse: 146913600.0000 - val_loss: 196099600.0000 - val_mse: 196099600.0000\n",
            "Epoch 193/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146964224.0000 - mse: 146964224.0000 - val_loss: 285496672.0000 - val_mse: 285496672.0000\n",
            "Epoch 194/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146846496.0000 - mse: 146846496.0000 - val_loss: 434901664.0000 - val_mse: 434901664.0000\n",
            "Epoch 195/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146285792.0000 - mse: 146285792.0000 - val_loss: 212315568.0000 - val_mse: 212315568.0000\n",
            "Epoch 196/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146333424.0000 - mse: 146333424.0000 - val_loss: 189268016.0000 - val_mse: 189268016.0000\n",
            "Epoch 197/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146438432.0000 - mse: 146438432.0000 - val_loss: 201212128.0000 - val_mse: 201212128.0000\n",
            "Epoch 198/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146039328.0000 - mse: 146039328.0000 - val_loss: 208536752.0000 - val_mse: 208536752.0000\n",
            "Epoch 199/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146339856.0000 - mse: 146339856.0000 - val_loss: 317915392.0000 - val_mse: 317915392.0000\n",
            "Epoch 200/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147302608.0000 - mse: 147302608.0000 - val_loss: 246889776.0000 - val_mse: 246889776.0000\n",
            "Epoch 201/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146785392.0000 - mse: 146785392.0000 - val_loss: 412872576.0000 - val_mse: 412872576.0000\n",
            "Epoch 202/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146655840.0000 - mse: 146655840.0000 - val_loss: 280162464.0000 - val_mse: 280162464.0000\n",
            "Epoch 203/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146462448.0000 - mse: 146462448.0000 - val_loss: 376044800.0000 - val_mse: 376044800.0000\n",
            "Epoch 204/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 145899008.0000 - mse: 145899008.0000 - val_loss: 200157040.0000 - val_mse: 200157040.0000\n",
            "Epoch 205/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 147010288.0000 - mse: 147010288.0000 - val_loss: 212901152.0000 - val_mse: 212901152.0000\n",
            "Epoch 206/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146789184.0000 - mse: 146789184.0000 - val_loss: 194108784.0000 - val_mse: 194108784.0000\n",
            "Epoch 207/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 145822672.0000 - mse: 145822672.0000 - val_loss: 201336800.0000 - val_mse: 201336800.0000\n",
            "Epoch 208/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145991824.0000 - mse: 145991824.0000 - val_loss: 262151680.0000 - val_mse: 262151680.0000\n",
            "Epoch 209/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 146003872.0000 - mse: 146003872.0000 - val_loss: 272945440.0000 - val_mse: 272945440.0000\n",
            "Epoch 210/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145516544.0000 - mse: 145516544.0000 - val_loss: 202196176.0000 - val_mse: 202196176.0000\n",
            "Epoch 211/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146398352.0000 - mse: 146398352.0000 - val_loss: 211145216.0000 - val_mse: 211145216.0000\n",
            "Epoch 212/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145443936.0000 - mse: 145443936.0000 - val_loss: 440984384.0000 - val_mse: 440984384.0000\n",
            "Epoch 213/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145860592.0000 - mse: 145860592.0000 - val_loss: 219399216.0000 - val_mse: 219399216.0000\n",
            "Epoch 214/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145709328.0000 - mse: 145709328.0000 - val_loss: 326313120.0000 - val_mse: 326313120.0000\n",
            "Epoch 215/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145824128.0000 - mse: 145824128.0000 - val_loss: 201209792.0000 - val_mse: 201209792.0000\n",
            "Epoch 216/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145518816.0000 - mse: 145518816.0000 - val_loss: 232451168.0000 - val_mse: 232451168.0000\n",
            "Epoch 217/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 146200816.0000 - mse: 146200816.0000 - val_loss: 213127296.0000 - val_mse: 213127296.0000\n",
            "Epoch 218/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 145040208.0000 - mse: 145040208.0000 - val_loss: 200384976.0000 - val_mse: 200384976.0000\n",
            "Epoch 219/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 145389680.0000 - mse: 145389680.0000 - val_loss: 300726528.0000 - val_mse: 300726528.0000\n",
            "Epoch 220/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145803072.0000 - mse: 145803072.0000 - val_loss: 215094032.0000 - val_mse: 215094032.0000\n",
            "Epoch 221/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145375280.0000 - mse: 145375280.0000 - val_loss: 298775040.0000 - val_mse: 298775040.0000\n",
            "Epoch 222/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145710608.0000 - mse: 145710608.0000 - val_loss: 223948032.0000 - val_mse: 223948032.0000\n",
            "Epoch 223/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 145986096.0000 - mse: 145986096.0000 - val_loss: 218189968.0000 - val_mse: 218189968.0000\n",
            "Epoch 224/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 145643360.0000 - mse: 145643360.0000 - val_loss: 242861984.0000 - val_mse: 242861984.0000\n",
            "Epoch 225/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145169120.0000 - mse: 145169120.0000 - val_loss: 191151200.0000 - val_mse: 191151200.0000\n",
            "Epoch 226/300\n",
            "1221/1221 [==============================] - 4s 4ms/step - loss: 145008256.0000 - mse: 145008256.0000 - val_loss: 297697824.0000 - val_mse: 297697824.0000\n",
            "Epoch 227/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145331600.0000 - mse: 145331600.0000 - val_loss: 189551344.0000 - val_mse: 189551344.0000\n",
            "Epoch 228/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145401472.0000 - mse: 145401472.0000 - val_loss: 258356688.0000 - val_mse: 258356688.0000\n",
            "Epoch 229/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144182640.0000 - mse: 144182640.0000 - val_loss: 219268688.0000 - val_mse: 219268688.0000\n",
            "Epoch 230/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145640000.0000 - mse: 145640000.0000 - val_loss: 331198656.0000 - val_mse: 331198656.0000\n",
            "Epoch 231/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145360400.0000 - mse: 145360400.0000 - val_loss: 198679680.0000 - val_mse: 198679680.0000\n",
            "Epoch 232/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144473680.0000 - mse: 144473680.0000 - val_loss: 415640672.0000 - val_mse: 415640672.0000\n",
            "Epoch 233/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144673888.0000 - mse: 144673888.0000 - val_loss: 267738688.0000 - val_mse: 267738688.0000\n",
            "Epoch 234/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144704624.0000 - mse: 144704624.0000 - val_loss: 185740848.0000 - val_mse: 185740848.0000\n",
            "Epoch 235/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145005760.0000 - mse: 145005760.0000 - val_loss: 194249344.0000 - val_mse: 194249344.0000\n",
            "Epoch 236/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145422144.0000 - mse: 145422144.0000 - val_loss: 276815872.0000 - val_mse: 276815872.0000\n",
            "Epoch 237/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145455136.0000 - mse: 145455136.0000 - val_loss: 200651328.0000 - val_mse: 200651328.0000\n",
            "Epoch 238/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144684208.0000 - mse: 144684208.0000 - val_loss: 324050048.0000 - val_mse: 324050048.0000\n",
            "Epoch 239/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145121424.0000 - mse: 145121424.0000 - val_loss: 307843808.0000 - val_mse: 307843808.0000\n",
            "Epoch 240/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144631072.0000 - mse: 144631072.0000 - val_loss: 371289280.0000 - val_mse: 371289280.0000\n",
            "Epoch 241/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144541520.0000 - mse: 144541520.0000 - val_loss: 317408736.0000 - val_mse: 317408736.0000\n",
            "Epoch 242/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 145556400.0000 - mse: 145556400.0000 - val_loss: 293622912.0000 - val_mse: 293622912.0000\n",
            "Epoch 243/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144411360.0000 - mse: 144411360.0000 - val_loss: 190182336.0000 - val_mse: 190182336.0000\n",
            "Epoch 244/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144559792.0000 - mse: 144559792.0000 - val_loss: 311546656.0000 - val_mse: 311546656.0000\n",
            "Epoch 245/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144905280.0000 - mse: 144905280.0000 - val_loss: 189509408.0000 - val_mse: 189509408.0000\n",
            "Epoch 246/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144562816.0000 - mse: 144562816.0000 - val_loss: 277131904.0000 - val_mse: 277131904.0000\n",
            "Epoch 247/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 143855408.0000 - mse: 143855408.0000 - val_loss: 205292880.0000 - val_mse: 205292880.0000\n",
            "Epoch 248/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144894736.0000 - mse: 144894736.0000 - val_loss: 234841152.0000 - val_mse: 234841152.0000\n",
            "Epoch 249/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144193936.0000 - mse: 144193936.0000 - val_loss: 333717984.0000 - val_mse: 333717984.0000\n",
            "Epoch 250/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144559232.0000 - mse: 144559232.0000 - val_loss: 183027984.0000 - val_mse: 183027984.0000\n",
            "Epoch 251/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 143901536.0000 - mse: 143901536.0000 - val_loss: 258048048.0000 - val_mse: 258048048.0000\n",
            "Epoch 252/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 143972496.0000 - mse: 143972496.0000 - val_loss: 256113504.0000 - val_mse: 256113504.0000\n",
            "Epoch 253/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 143738176.0000 - mse: 143738176.0000 - val_loss: 205765328.0000 - val_mse: 205765328.0000\n",
            "Epoch 254/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144424032.0000 - mse: 144424032.0000 - val_loss: 201667184.0000 - val_mse: 201667184.0000\n",
            "Epoch 255/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 143768720.0000 - mse: 143768720.0000 - val_loss: 245678480.0000 - val_mse: 245678480.0000\n",
            "Epoch 256/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 143959648.0000 - mse: 143959648.0000 - val_loss: 238818928.0000 - val_mse: 238818928.0000\n",
            "Epoch 257/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 143974864.0000 - mse: 143974864.0000 - val_loss: 224986928.0000 - val_mse: 224986928.0000\n",
            "Epoch 258/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 143581808.0000 - mse: 143581808.0000 - val_loss: 298877888.0000 - val_mse: 298877888.0000\n",
            "Epoch 259/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144359456.0000 - mse: 144359456.0000 - val_loss: 237613600.0000 - val_mse: 237613600.0000\n",
            "Epoch 260/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 143998896.0000 - mse: 143998896.0000 - val_loss: 259161744.0000 - val_mse: 259161744.0000\n",
            "Epoch 261/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 144164064.0000 - mse: 144164064.0000 - val_loss: 284696896.0000 - val_mse: 284696896.0000\n",
            "Epoch 262/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 143342384.0000 - mse: 143342384.0000 - val_loss: 309432160.0000 - val_mse: 309432160.0000\n",
            "Epoch 263/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 143705280.0000 - mse: 143705280.0000 - val_loss: 292394752.0000 - val_mse: 292394752.0000\n",
            "Epoch 264/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 143340336.0000 - mse: 143340336.0000 - val_loss: 253748624.0000 - val_mse: 253748624.0000\n",
            "Epoch 265/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 143024880.0000 - mse: 143024880.0000 - val_loss: 178647920.0000 - val_mse: 178647920.0000\n",
            "Epoch 266/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 143390096.0000 - mse: 143390096.0000 - val_loss: 188084848.0000 - val_mse: 188084848.0000\n",
            "Epoch 267/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 143070720.0000 - mse: 143070720.0000 - val_loss: 219623760.0000 - val_mse: 219623760.0000\n",
            "Epoch 268/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 142880576.0000 - mse: 142880576.0000 - val_loss: 194210288.0000 - val_mse: 194210288.0000\n",
            "Epoch 269/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 142991616.0000 - mse: 142991616.0000 - val_loss: 179812160.0000 - val_mse: 179812160.0000\n",
            "Epoch 270/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 142745840.0000 - mse: 142745840.0000 - val_loss: 258527184.0000 - val_mse: 258527184.0000\n",
            "Epoch 271/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 143271808.0000 - mse: 143271808.0000 - val_loss: 221316912.0000 - val_mse: 221316912.0000\n",
            "Epoch 272/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 142303776.0000 - mse: 142303776.0000 - val_loss: 208190992.0000 - val_mse: 208190992.0000\n",
            "Epoch 273/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 142969024.0000 - mse: 142969024.0000 - val_loss: 298387840.0000 - val_mse: 298387840.0000\n",
            "Epoch 274/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 142196016.0000 - mse: 142196016.0000 - val_loss: 199583856.0000 - val_mse: 199583856.0000\n",
            "Epoch 275/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 142185616.0000 - mse: 142185616.0000 - val_loss: 321250784.0000 - val_mse: 321250784.0000\n",
            "Epoch 276/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 142008240.0000 - mse: 142008240.0000 - val_loss: 299695392.0000 - val_mse: 299695392.0000\n",
            "Epoch 277/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 142136992.0000 - mse: 142136992.0000 - val_loss: 203445392.0000 - val_mse: 203445392.0000\n",
            "Epoch 278/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 142866256.0000 - mse: 142866256.0000 - val_loss: 330245376.0000 - val_mse: 330245376.0000\n",
            "Epoch 279/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 141714848.0000 - mse: 141714848.0000 - val_loss: 468205664.0000 - val_mse: 468205664.0000\n",
            "Epoch 280/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 141761600.0000 - mse: 141761600.0000 - val_loss: 394202528.0000 - val_mse: 394202528.0000\n",
            "Epoch 281/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 142539088.0000 - mse: 142539088.0000 - val_loss: 183894480.0000 - val_mse: 183894480.0000\n",
            "Epoch 282/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 142208224.0000 - mse: 142208224.0000 - val_loss: 206787696.0000 - val_mse: 206787696.0000\n",
            "Epoch 283/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 141600128.0000 - mse: 141600128.0000 - val_loss: 199913920.0000 - val_mse: 199913920.0000\n",
            "Epoch 284/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 141691408.0000 - mse: 141691408.0000 - val_loss: 178952112.0000 - val_mse: 178952112.0000\n",
            "Epoch 285/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 141687664.0000 - mse: 141687664.0000 - val_loss: 286073792.0000 - val_mse: 286073792.0000\n",
            "Epoch 286/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 142053312.0000 - mse: 142053312.0000 - val_loss: 272740640.0000 - val_mse: 272740640.0000\n",
            "Epoch 287/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 142170352.0000 - mse: 142170352.0000 - val_loss: 196683136.0000 - val_mse: 196683136.0000\n",
            "Epoch 288/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 141930240.0000 - mse: 141930240.0000 - val_loss: 227754512.0000 - val_mse: 227754512.0000\n",
            "Epoch 289/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 141960640.0000 - mse: 141960640.0000 - val_loss: 219325248.0000 - val_mse: 219325248.0000\n",
            "Epoch 290/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 141640256.0000 - mse: 141640256.0000 - val_loss: 199073424.0000 - val_mse: 199073424.0000\n",
            "Epoch 291/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 141597856.0000 - mse: 141597856.0000 - val_loss: 245082080.0000 - val_mse: 245082080.0000\n",
            "Epoch 292/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 141534816.0000 - mse: 141534816.0000 - val_loss: 212938240.0000 - val_mse: 212938240.0000\n",
            "Epoch 293/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 141794208.0000 - mse: 141794208.0000 - val_loss: 218680576.0000 - val_mse: 218680576.0000\n",
            "Epoch 294/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 141191344.0000 - mse: 141191344.0000 - val_loss: 514284224.0000 - val_mse: 514284224.0000\n",
            "Epoch 295/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 140967744.0000 - mse: 140967744.0000 - val_loss: 378356160.0000 - val_mse: 378356160.0000\n",
            "Epoch 296/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 141639808.0000 - mse: 141639808.0000 - val_loss: 187671152.0000 - val_mse: 187671152.0000\n",
            "Epoch 297/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 141041760.0000 - mse: 141041760.0000 - val_loss: 368006048.0000 - val_mse: 368006048.0000\n",
            "Epoch 298/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 140651440.0000 - mse: 140651440.0000 - val_loss: 202838096.0000 - val_mse: 202838096.0000\n",
            "Epoch 299/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 141281936.0000 - mse: 141281936.0000 - val_loss: 248010160.0000 - val_mse: 248010160.0000\n",
            "Epoch 300/300\n",
            "1221/1221 [==============================] - 5s 4ms/step - loss: 140759280.0000 - mse: 140759280.0000 - val_loss: 229369680.0000 - val_mse: 229369680.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M31G8EDDAPW"
      },
      "source": [
        "#batch size 줄이니까 val_mse 229369680.0000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve-6NNWU5hfx",
        "outputId": "1cbdc351-67f6-414e-8be7-15f508f68b28"
      },
      "source": [
        "from keras.layers import BatchNormalization, Dropout\n",
        "def build_model2():\n",
        "  model2 = keras.Sequential([\n",
        "    layers.Dense(256, activation='relu', input_shape=[len(train_tune_cbe.keys())]),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.0001)\n",
        "\n",
        "  model2.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mse'])\n",
        "  return model2\n",
        "model2=build_model2()\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 256)               2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 22,273\n",
            "Trainable params: 21,569\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8qTICBU_Qj8",
        "outputId": "e897cca3-faaf-4fc5-d988-5ffe68cc88ba"
      },
      "source": [
        "history = model2.fit(train_tune_cbe, train_tune_y, epochs=300, validation_data = (val_cbe, val_y), batch_size = 512)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "611/611 [==============================] - 7s 10ms/step - loss: 3084856298.2484 - mse: 3084856298.2484 - val_loss: 4171169792.0000 - val_mse: 4171169792.0000\n",
            "Epoch 2/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3069600261.4379 - mse: 3069600261.4379 - val_loss: 4170322176.0000 - val_mse: 4170322176.0000\n",
            "Epoch 3/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3065429398.1699 - mse: 3065429398.1699 - val_loss: 4170484224.0000 - val_mse: 4170484224.0000\n",
            "Epoch 4/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3074639480.4706 - mse: 3074639480.4706 - val_loss: 4171201280.0000 - val_mse: 4171201280.0000\n",
            "Epoch 5/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3074492075.0850 - mse: 3074492075.0850 - val_loss: 4169013248.0000 - val_mse: 4169013248.0000\n",
            "Epoch 6/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3090581196.9673 - mse: 3090581196.9673 - val_loss: 4168369664.0000 - val_mse: 4168369664.0000\n",
            "Epoch 7/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3065090293.9608 - mse: 3065090293.9608 - val_loss: 4168090368.0000 - val_mse: 4168090368.0000\n",
            "Epoch 8/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3093601226.8758 - mse: 3093601226.8758 - val_loss: 4167628544.0000 - val_mse: 4167628544.0000\n",
            "Epoch 9/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3079573887.1634 - mse: 3079573887.1634 - val_loss: 4167715584.0000 - val_mse: 4167715584.0000\n",
            "Epoch 10/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3078278772.2876 - mse: 3078278772.2876 - val_loss: 4168573952.0000 - val_mse: 4168573952.0000\n",
            "Epoch 11/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3074795068.6536 - mse: 3074795068.6536 - val_loss: 4164598272.0000 - val_mse: 4164598272.0000\n",
            "Epoch 12/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3063380772.3922 - mse: 3063380772.3922 - val_loss: 4166028544.0000 - val_mse: 4166028544.0000\n",
            "Epoch 13/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3091459755.9216 - mse: 3091459755.9216 - val_loss: 4164916992.0000 - val_mse: 4164916992.0000\n",
            "Epoch 14/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3074083446.7974 - mse: 3074083446.7974 - val_loss: 4166330112.0000 - val_mse: 4166330112.0000\n",
            "Epoch 15/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3060721594.9804 - mse: 3060721594.9804 - val_loss: 4159962880.0000 - val_mse: 4159962880.0000\n",
            "Epoch 16/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3042681166.6405 - mse: 3042681166.6405 - val_loss: 4159837952.0000 - val_mse: 4159837952.0000\n",
            "Epoch 17/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3060531189.5425 - mse: 3060531189.5425 - val_loss: 4160924416.0000 - val_mse: 4160924416.0000\n",
            "Epoch 18/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3059747551.3725 - mse: 3059747551.3725 - val_loss: 4159713536.0000 - val_mse: 4159713536.0000\n",
            "Epoch 19/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3069490902.1699 - mse: 3069490902.1699 - val_loss: 4156718080.0000 - val_mse: 4156718080.0000\n",
            "Epoch 20/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3064785850.1438 - mse: 3064785850.1438 - val_loss: 4157472256.0000 - val_mse: 4157472256.0000\n",
            "Epoch 21/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3064215295.5817 - mse: 3064215295.5817 - val_loss: 4160881920.0000 - val_mse: 4160881920.0000\n",
            "Epoch 22/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3069664105.8301 - mse: 3069664105.8301 - val_loss: 4152859392.0000 - val_mse: 4152859392.0000\n",
            "Epoch 23/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3064998490.7712 - mse: 3064998490.7712 - val_loss: 4154282240.0000 - val_mse: 4154282240.0000\n",
            "Epoch 24/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3057055757.3856 - mse: 3057055757.3856 - val_loss: 4153643008.0000 - val_mse: 4153643008.0000\n",
            "Epoch 25/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3059674196.4967 - mse: 3059674196.4967 - val_loss: 4148399616.0000 - val_mse: 4148399616.0000\n",
            "Epoch 26/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3062852098.5098 - mse: 3062852098.5098 - val_loss: 4146552832.0000 - val_mse: 4146552832.0000\n",
            "Epoch 27/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3044788624.3137 - mse: 3044788624.3137 - val_loss: 4143069184.0000 - val_mse: 4143069184.0000\n",
            "Epoch 28/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3062784539.1895 - mse: 3062784539.1895 - val_loss: 4150045952.0000 - val_mse: 4150045952.0000\n",
            "Epoch 29/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3058817288.7843 - mse: 3058817288.7843 - val_loss: 4142951424.0000 - val_mse: 4142951424.0000\n",
            "Epoch 30/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3058903400.5752 - mse: 3058903400.5752 - val_loss: 4142218496.0000 - val_mse: 4142218496.0000\n",
            "Epoch 31/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3031541667.5556 - mse: 3031541667.5556 - val_loss: 4155244288.0000 - val_mse: 4155244288.0000\n",
            "Epoch 32/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3065594390.1699 - mse: 3065594390.1699 - val_loss: 4141437440.0000 - val_mse: 4141437440.0000\n",
            "Epoch 33/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3041250194.4052 - mse: 3041250194.4052 - val_loss: 4131914752.0000 - val_mse: 4131914752.0000\n",
            "Epoch 34/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3059492204.7582 - mse: 3059492204.7582 - val_loss: 4137459456.0000 - val_mse: 4137459456.0000\n",
            "Epoch 35/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3062674764.5490 - mse: 3062674764.5490 - val_loss: 4123065088.0000 - val_mse: 4123065088.0000\n",
            "Epoch 36/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3057144081.9869 - mse: 3057144081.9869 - val_loss: 4132086528.0000 - val_mse: 4132086528.0000\n",
            "Epoch 37/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3031838699.5033 - mse: 3031838699.5033 - val_loss: 4129054464.0000 - val_mse: 4129054464.0000\n",
            "Epoch 38/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3031942687.7908 - mse: 3031942687.7908 - val_loss: 4128557312.0000 - val_mse: 4128557312.0000\n",
            "Epoch 39/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3041968205.3856 - mse: 3041968205.3856 - val_loss: 4122897408.0000 - val_mse: 4122897408.0000\n",
            "Epoch 40/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3053543703.0065 - mse: 3053543703.0065 - val_loss: 4126027008.0000 - val_mse: 4126027008.0000\n",
            "Epoch 41/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3031255911.7386 - mse: 3031255911.7386 - val_loss: 4112674048.0000 - val_mse: 4112674048.0000\n",
            "Epoch 42/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3046687933.0719 - mse: 3046687933.0719 - val_loss: 4114997248.0000 - val_mse: 4114997248.0000\n",
            "Epoch 43/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3012741313.6732 - mse: 3012741313.6732 - val_loss: 4129702400.0000 - val_mse: 4129702400.0000\n",
            "Epoch 44/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3069982726.6928 - mse: 3069982726.6928 - val_loss: 4118099456.0000 - val_mse: 4118099456.0000\n",
            "Epoch 45/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3046238525.0719 - mse: 3046238525.0719 - val_loss: 4122638080.0000 - val_mse: 4122638080.0000\n",
            "Epoch 46/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3043290080.6275 - mse: 3043290080.6275 - val_loss: 4120174592.0000 - val_mse: 4120174592.0000\n",
            "Epoch 47/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3034371021.8039 - mse: 3034371021.8039 - val_loss: 4113009408.0000 - val_mse: 4113009408.0000\n",
            "Epoch 48/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3034027525.8562 - mse: 3034027525.8562 - val_loss: 4101830912.0000 - val_mse: 4101830912.0000\n",
            "Epoch 49/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3009922879.1634 - mse: 3009922879.1634 - val_loss: 4104639232.0000 - val_mse: 4104639232.0000\n",
            "Epoch 50/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3030094502.0654 - mse: 3030094502.0654 - val_loss: 4091307776.0000 - val_mse: 4091307776.0000\n",
            "Epoch 51/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3018368017.5686 - mse: 3018368017.5686 - val_loss: 4100564224.0000 - val_mse: 4100564224.0000\n",
            "Epoch 52/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3024941088.2092 - mse: 3024941088.2092 - val_loss: 4111798784.0000 - val_mse: 4111798784.0000\n",
            "Epoch 53/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3002831091.4510 - mse: 3002831091.4510 - val_loss: 4092544512.0000 - val_mse: 4092544512.0000\n",
            "Epoch 54/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3019357041.7778 - mse: 3019357041.7778 - val_loss: 4077302016.0000 - val_mse: 4077302016.0000\n",
            "Epoch 55/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3030812434.8235 - mse: 3030812434.8235 - val_loss: 4089698560.0000 - val_mse: 4089698560.0000\n",
            "Epoch 56/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3035090758.2745 - mse: 3035090758.2745 - val_loss: 4108385536.0000 - val_mse: 4108385536.0000\n",
            "Epoch 57/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3009023526.0654 - mse: 3009023526.0654 - val_loss: 4088346880.0000 - val_mse: 4088346880.0000\n",
            "Epoch 58/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3015133971.2418 - mse: 3015133971.2418 - val_loss: 4066497792.0000 - val_mse: 4066497792.0000\n",
            "Epoch 59/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2998545384.1569 - mse: 2998545384.1569 - val_loss: 4107812352.0000 - val_mse: 4107812352.0000\n",
            "Epoch 60/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3006696900.1830 - mse: 3006696900.1830 - val_loss: 4069112576.0000 - val_mse: 4069112576.0000\n",
            "Epoch 61/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2990303932.2353 - mse: 2990303932.2353 - val_loss: 4072404480.0000 - val_mse: 4072404480.0000\n",
            "Epoch 62/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2991454735.0588 - mse: 2991454735.0588 - val_loss: 4052906752.0000 - val_mse: 4052906752.0000\n",
            "Epoch 63/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 3008053096.5752 - mse: 3008053096.5752 - val_loss: 4072271104.0000 - val_mse: 4072271104.0000\n",
            "Epoch 64/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2973363885.5948 - mse: 2973363885.5948 - val_loss: 4076169984.0000 - val_mse: 4076169984.0000\n",
            "Epoch 65/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2973077078.5882 - mse: 2973077078.5882 - val_loss: 4061314560.0000 - val_mse: 4061314560.0000\n",
            "Epoch 66/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2993383646.5359 - mse: 2993383646.5359 - val_loss: 4092387584.0000 - val_mse: 4092387584.0000\n",
            "Epoch 67/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2978436701.6993 - mse: 2978436701.6993 - val_loss: 4061649664.0000 - val_mse: 4061649664.0000\n",
            "Epoch 68/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2965279188.4967 - mse: 2965279188.4967 - val_loss: 4062427136.0000 - val_mse: 4062427136.0000\n",
            "Epoch 69/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2992632748.7582 - mse: 2992632748.7582 - val_loss: 4039482112.0000 - val_mse: 4039482112.0000\n",
            "Epoch 70/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2995719751.9477 - mse: 2995719751.9477 - val_loss: 4056118016.0000 - val_mse: 4056118016.0000\n",
            "Epoch 71/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2997569930.4575 - mse: 2997569930.4575 - val_loss: 4008365568.0000 - val_mse: 4008365568.0000\n",
            "Epoch 72/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2964757476.3922 - mse: 2964757476.3922 - val_loss: 3982594048.0000 - val_mse: 3982594048.0000\n",
            "Epoch 73/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2983014118.0654 - mse: 2983014118.0654 - val_loss: 4038409472.0000 - val_mse: 4038409472.0000\n",
            "Epoch 74/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2958828272.5229 - mse: 2958828272.5229 - val_loss: 4016346368.0000 - val_mse: 4016346368.0000\n",
            "Epoch 75/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2963329088.4183 - mse: 2963329088.4183 - val_loss: 4013125376.0000 - val_mse: 4013125376.0000\n",
            "Epoch 76/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2959426730.2484 - mse: 2959426730.2484 - val_loss: 4006032384.0000 - val_mse: 4006032384.0000\n",
            "Epoch 77/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2953541280.2092 - mse: 2953541280.2092 - val_loss: 4032225536.0000 - val_mse: 4032225536.0000\n",
            "Epoch 78/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2945801129.4118 - mse: 2945801129.4118 - val_loss: 3983995648.0000 - val_mse: 3983995648.0000\n",
            "Epoch 79/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2948598040.6797 - mse: 2948598040.6797 - val_loss: 3981359872.0000 - val_mse: 3981359872.0000\n",
            "Epoch 80/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2969143256.6797 - mse: 2969143256.6797 - val_loss: 3993425920.0000 - val_mse: 3993425920.0000\n",
            "Epoch 81/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2942518283.7124 - mse: 2942518283.7124 - val_loss: 4009459200.0000 - val_mse: 4009459200.0000\n",
            "Epoch 82/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2918887133.6993 - mse: 2918887133.6993 - val_loss: 3975531520.0000 - val_mse: 3975531520.0000\n",
            "Epoch 83/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2938801100.9673 - mse: 2938801100.9673 - val_loss: 3994448640.0000 - val_mse: 3994448640.0000\n",
            "Epoch 84/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2953978278.9020 - mse: 2953978278.9020 - val_loss: 3975439360.0000 - val_mse: 3975439360.0000\n",
            "Epoch 85/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2924458816.8366 - mse: 2924458816.8366 - val_loss: 3979262976.0000 - val_mse: 3979262976.0000\n",
            "Epoch 86/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2914821414.0654 - mse: 2914821414.0654 - val_loss: 3966689792.0000 - val_mse: 3966689792.0000\n",
            "Epoch 87/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2934869139.6601 - mse: 2934869139.6601 - val_loss: 3956510976.0000 - val_mse: 3956510976.0000\n",
            "Epoch 88/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2907762398.5359 - mse: 2907762398.5359 - val_loss: 3957921024.0000 - val_mse: 3957921024.0000\n",
            "Epoch 89/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2922954207.3725 - mse: 2922954207.3725 - val_loss: 3955306496.0000 - val_mse: 3955306496.0000\n",
            "Epoch 90/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2922237926.4837 - mse: 2922237926.4837 - val_loss: 3944678400.0000 - val_mse: 3944678400.0000\n",
            "Epoch 91/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2910190409.2026 - mse: 2910190409.2026 - val_loss: 3979360256.0000 - val_mse: 3979360256.0000\n",
            "Epoch 92/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2914542751.3725 - mse: 2914542751.3725 - val_loss: 3951144960.0000 - val_mse: 3951144960.0000\n",
            "Epoch 93/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2926748231.9477 - mse: 2926748231.9477 - val_loss: 3916975360.0000 - val_mse: 3916975360.0000\n",
            "Epoch 94/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2912462538.8758 - mse: 2912462538.8758 - val_loss: 3926761728.0000 - val_mse: 3926761728.0000\n",
            "Epoch 95/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2903010908.4444 - mse: 2903010908.4444 - val_loss: 3946223104.0000 - val_mse: 3946223104.0000\n",
            "Epoch 96/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2882198991.0588 - mse: 2882198991.0588 - val_loss: 3977714688.0000 - val_mse: 3977714688.0000\n",
            "Epoch 97/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2903598986.4575 - mse: 2903598986.4575 - val_loss: 3950995968.0000 - val_mse: 3950995968.0000\n",
            "Epoch 98/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2909111831.0065 - mse: 2909111831.0065 - val_loss: 3905243136.0000 - val_mse: 3905243136.0000\n",
            "Epoch 99/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2879075789.3856 - mse: 2879075789.3856 - val_loss: 3904557568.0000 - val_mse: 3904557568.0000\n",
            "Epoch 100/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2870487258.7712 - mse: 2870487258.7712 - val_loss: 3908102912.0000 - val_mse: 3908102912.0000\n",
            "Epoch 101/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2886069603.1373 - mse: 2886069603.1373 - val_loss: 3891371008.0000 - val_mse: 3891371008.0000\n",
            "Epoch 102/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2866717059.7647 - mse: 2866717059.7647 - val_loss: 3893125120.0000 - val_mse: 3893125120.0000\n",
            "Epoch 103/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2840970075.6078 - mse: 2840970075.6078 - val_loss: 3870180096.0000 - val_mse: 3870180096.0000\n",
            "Epoch 104/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2844672928.2092 - mse: 2844672928.2092 - val_loss: 3958403584.0000 - val_mse: 3958403584.0000\n",
            "Epoch 105/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2866445688.0523 - mse: 2866445688.0523 - val_loss: 3833032960.0000 - val_mse: 3833032960.0000\n",
            "Epoch 106/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2858415152.1046 - mse: 2858415152.1046 - val_loss: 3838760448.0000 - val_mse: 3838760448.0000\n",
            "Epoch 107/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2847739153.9869 - mse: 2847739153.9869 - val_loss: 3852762880.0000 - val_mse: 3852762880.0000\n",
            "Epoch 108/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2829645989.6471 - mse: 2829645989.6471 - val_loss: 3937380352.0000 - val_mse: 3937380352.0000\n",
            "Epoch 109/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2852789449.6209 - mse: 2852789449.6209 - val_loss: 3827291648.0000 - val_mse: 3827291648.0000\n",
            "Epoch 110/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2851063032.0523 - mse: 2851063032.0523 - val_loss: 3874365440.0000 - val_mse: 3874365440.0000\n",
            "Epoch 111/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2883541071.0588 - mse: 2883541071.0588 - val_loss: 3882886400.0000 - val_mse: 3882886400.0000\n",
            "Epoch 112/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2799522915.5556 - mse: 2799522915.5556 - val_loss: 3848530176.0000 - val_mse: 3848530176.0000\n",
            "Epoch 113/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2865367163.8170 - mse: 2865367163.8170 - val_loss: 3809415680.0000 - val_mse: 3809415680.0000\n",
            "Epoch 114/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2823668673.6732 - mse: 2823668673.6732 - val_loss: 3804901632.0000 - val_mse: 3804901632.0000\n",
            "Epoch 115/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2833507138.5098 - mse: 2833507138.5098 - val_loss: 3786488832.0000 - val_mse: 3786488832.0000\n",
            "Epoch 116/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2813924320.2092 - mse: 2813924320.2092 - val_loss: 3786380288.0000 - val_mse: 3786380288.0000\n",
            "Epoch 117/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2816927362.0915 - mse: 2816927362.0915 - val_loss: 3790108928.0000 - val_mse: 3790108928.0000\n",
            "Epoch 118/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2796017483.7124 - mse: 2796017483.7124 - val_loss: 3822642944.0000 - val_mse: 3822642944.0000\n",
            "Epoch 119/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2813170063.4771 - mse: 2813170063.4771 - val_loss: 3809869312.0000 - val_mse: 3809869312.0000\n",
            "Epoch 120/300\n",
            "611/611 [==============================] - 6s 9ms/step - loss: 2824327486.7451 - mse: 2824327486.7451 - val_loss: 3792500480.0000 - val_mse: 3792500480.0000\n",
            "Epoch 121/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2806891818.6667 - mse: 2806891818.6667 - val_loss: 3778311424.0000 - val_mse: 3778311424.0000\n",
            "Epoch 122/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2788619363.1373 - mse: 2788619363.1373 - val_loss: 3770469632.0000 - val_mse: 3770469632.0000\n",
            "Epoch 123/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2800830529.2549 - mse: 2800830529.2549 - val_loss: 3737386240.0000 - val_mse: 3737386240.0000\n",
            "Epoch 124/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2782290864.5229 - mse: 2782290864.5229 - val_loss: 3818042368.0000 - val_mse: 3818042368.0000\n",
            "Epoch 125/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2814576868.3922 - mse: 2814576868.3922 - val_loss: 3754887680.0000 - val_mse: 3754887680.0000\n",
            "Epoch 126/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2767542649.7255 - mse: 2767542649.7255 - val_loss: 3768883968.0000 - val_mse: 3768883968.0000\n",
            "Epoch 127/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2762937832.1569 - mse: 2762937832.1569 - val_loss: 3808624896.0000 - val_mse: 3808624896.0000\n",
            "Epoch 128/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2770137868.1307 - mse: 2770137868.1307 - val_loss: 3758749184.0000 - val_mse: 3758749184.0000\n",
            "Epoch 129/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2759267573.1242 - mse: 2759267573.1242 - val_loss: 3755069952.0000 - val_mse: 3755069952.0000\n",
            "Epoch 130/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2759427145.2026 - mse: 2759427145.2026 - val_loss: 3809963520.0000 - val_mse: 3809963520.0000\n",
            "Epoch 131/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2767474108.2353 - mse: 2767474108.2353 - val_loss: 3715633152.0000 - val_mse: 3715633152.0000\n",
            "Epoch 132/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2758632322.5098 - mse: 2758632322.5098 - val_loss: 3725003008.0000 - val_mse: 3725003008.0000\n",
            "Epoch 133/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2733795869.6993 - mse: 2733795869.6993 - val_loss: 3802522368.0000 - val_mse: 3802522368.0000\n",
            "Epoch 134/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2752229181.0719 - mse: 2752229181.0719 - val_loss: 3713946624.0000 - val_mse: 3713946624.0000\n",
            "Epoch 135/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2734817605.4379 - mse: 2734817605.4379 - val_loss: 3720813056.0000 - val_mse: 3720813056.0000\n",
            "Epoch 136/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2731242715.1895 - mse: 2731242715.1895 - val_loss: 3696257536.0000 - val_mse: 3696257536.0000\n",
            "Epoch 137/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2727992911.4771 - mse: 2727992911.4771 - val_loss: 3715653376.0000 - val_mse: 3715653376.0000\n",
            "Epoch 138/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2713428552.7843 - mse: 2713428552.7843 - val_loss: 3778461952.0000 - val_mse: 3778461952.0000\n",
            "Epoch 139/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2719077414.9020 - mse: 2719077414.9020 - val_loss: 3707590656.0000 - val_mse: 3707590656.0000\n",
            "Epoch 140/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2716024340.0784 - mse: 2716024340.0784 - val_loss: 3642812928.0000 - val_mse: 3642812928.0000\n",
            "Epoch 141/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2708536682.6667 - mse: 2708536682.6667 - val_loss: 3779299584.0000 - val_mse: 3779299584.0000\n",
            "Epoch 142/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2706145654.3791 - mse: 2706145654.3791 - val_loss: 3659942912.0000 - val_mse: 3659942912.0000\n",
            "Epoch 143/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2705924833.8824 - mse: 2705924833.8824 - val_loss: 3641632768.0000 - val_mse: 3641632768.0000\n",
            "Epoch 144/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2713814998.1699 - mse: 2713814998.1699 - val_loss: 3713123072.0000 - val_mse: 3713123072.0000\n",
            "Epoch 145/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2681039205.2288 - mse: 2681039205.2288 - val_loss: 3643235328.0000 - val_mse: 3643235328.0000\n",
            "Epoch 146/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2708841949.6993 - mse: 2708841949.6993 - val_loss: 3588984064.0000 - val_mse: 3588984064.0000\n",
            "Epoch 147/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2694784118.7974 - mse: 2694784118.7974 - val_loss: 3656893696.0000 - val_mse: 3656893696.0000\n",
            "Epoch 148/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2661630711.2157 - mse: 2661630711.2157 - val_loss: 3645743872.0000 - val_mse: 3645743872.0000\n",
            "Epoch 149/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2654684597.9608 - mse: 2654684597.9608 - val_loss: 3619253760.0000 - val_mse: 3619253760.0000\n",
            "Epoch 150/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2666985783.2157 - mse: 2666985783.2157 - val_loss: 3675749376.0000 - val_mse: 3675749376.0000\n",
            "Epoch 151/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2633912054.7974 - mse: 2633912054.7974 - val_loss: 3611751424.0000 - val_mse: 3611751424.0000\n",
            "Epoch 152/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2635136956.2353 - mse: 2635136956.2353 - val_loss: 3687301888.0000 - val_mse: 3687301888.0000\n",
            "Epoch 153/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2630701444.6013 - mse: 2630701444.6013 - val_loss: 3571950336.0000 - val_mse: 3571950336.0000\n",
            "Epoch 154/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2628518302.1176 - mse: 2628518302.1176 - val_loss: 3620839424.0000 - val_mse: 3620839424.0000\n",
            "Epoch 155/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2626681487.8954 - mse: 2626681487.8954 - val_loss: 3579773184.0000 - val_mse: 3579773184.0000\n",
            "Epoch 156/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2621433505.8824 - mse: 2621433505.8824 - val_loss: 3566994176.0000 - val_mse: 3566994176.0000\n",
            "Epoch 157/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2624596834.3007 - mse: 2624596834.3007 - val_loss: 3554118400.0000 - val_mse: 3554118400.0000\n",
            "Epoch 158/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2611166927.0588 - mse: 2611166927.0588 - val_loss: 3571681792.0000 - val_mse: 3571681792.0000\n",
            "Epoch 159/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2631861921.0458 - mse: 2631861921.0458 - val_loss: 3586038272.0000 - val_mse: 3586038272.0000\n",
            "Epoch 160/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2622075177.4118 - mse: 2622075177.4118 - val_loss: 3575432960.0000 - val_mse: 3575432960.0000\n",
            "Epoch 161/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2627031583.3725 - mse: 2627031583.3725 - val_loss: 3567402752.0000 - val_mse: 3567402752.0000\n",
            "Epoch 162/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2591295510.1699 - mse: 2591295510.1699 - val_loss: 3486280448.0000 - val_mse: 3486280448.0000\n",
            "Epoch 163/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2606041218.0915 - mse: 2606041218.0915 - val_loss: 3528311040.0000 - val_mse: 3528311040.0000\n",
            "Epoch 164/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2585496787.2418 - mse: 2585496787.2418 - val_loss: 3682808576.0000 - val_mse: 3682808576.0000\n",
            "Epoch 165/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2610592498.6144 - mse: 2610592498.6144 - val_loss: 3513945344.0000 - val_mse: 3513945344.0000\n",
            "Epoch 166/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2588727171.3464 - mse: 2588727171.3464 - val_loss: 3497248256.0000 - val_mse: 3497248256.0000\n",
            "Epoch 167/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2575126308.3922 - mse: 2575126308.3922 - val_loss: 3415580416.0000 - val_mse: 3415580416.0000\n",
            "Epoch 168/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2585041712.9412 - mse: 2585041712.9412 - val_loss: 3534163456.0000 - val_mse: 3534163456.0000\n",
            "Epoch 169/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2558304097.8824 - mse: 2558304097.8824 - val_loss: 3405647104.0000 - val_mse: 3405647104.0000\n",
            "Epoch 170/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2554997277.2810 - mse: 2554997277.2810 - val_loss: 3428196864.0000 - val_mse: 3428196864.0000\n",
            "Epoch 171/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2586212665.7255 - mse: 2586212665.7255 - val_loss: 3457473536.0000 - val_mse: 3457473536.0000\n",
            "Epoch 172/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2540984313.3072 - mse: 2540984313.3072 - val_loss: 3397294080.0000 - val_mse: 3397294080.0000\n",
            "Epoch 173/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2540210501.4379 - mse: 2540210501.4379 - val_loss: 3409094912.0000 - val_mse: 3409094912.0000\n",
            "Epoch 174/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2539266413.5948 - mse: 2539266413.5948 - val_loss: 3400948736.0000 - val_mse: 3400948736.0000\n",
            "Epoch 175/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2549612292.6013 - mse: 2549612292.6013 - val_loss: 3369782528.0000 - val_mse: 3369782528.0000\n",
            "Epoch 176/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2520486062.4314 - mse: 2520486062.4314 - val_loss: 3465343232.0000 - val_mse: 3465343232.0000\n",
            "Epoch 177/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2532213859.1373 - mse: 2532213859.1373 - val_loss: 3564002048.0000 - val_mse: 3564002048.0000\n",
            "Epoch 178/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2515399273.8301 - mse: 2515399273.8301 - val_loss: 3332593664.0000 - val_mse: 3332593664.0000\n",
            "Epoch 179/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2523941018.7712 - mse: 2523941018.7712 - val_loss: 3320623360.0000 - val_mse: 3320623360.0000\n",
            "Epoch 180/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2489357345.8824 - mse: 2489357345.8824 - val_loss: 3411015680.0000 - val_mse: 3411015680.0000\n",
            "Epoch 181/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2493340288.8366 - mse: 2493340288.8366 - val_loss: 3410458112.0000 - val_mse: 3410458112.0000\n",
            "Epoch 182/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2496597601.0458 - mse: 2496597601.0458 - val_loss: 3309888512.0000 - val_mse: 3309888512.0000\n",
            "Epoch 183/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2484797135.0588 - mse: 2484797135.0588 - val_loss: 3383123712.0000 - val_mse: 3383123712.0000\n",
            "Epoch 184/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2489717882.5621 - mse: 2489717882.5621 - val_loss: 3300822784.0000 - val_mse: 3300822784.0000\n",
            "Epoch 185/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2481236802.5098 - mse: 2481236802.5098 - val_loss: 3311854080.0000 - val_mse: 3311854080.0000\n",
            "Epoch 186/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2448691533.8039 - mse: 2448691533.8039 - val_loss: 3256972800.0000 - val_mse: 3256972800.0000\n",
            "Epoch 187/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2463166521.7255 - mse: 2463166521.7255 - val_loss: 3400090112.0000 - val_mse: 3400090112.0000\n",
            "Epoch 188/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2455626254.2222 - mse: 2455626254.2222 - val_loss: 3525397760.0000 - val_mse: 3525397760.0000\n",
            "Epoch 189/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2443859597.8039 - mse: 2443859597.8039 - val_loss: 3351293952.0000 - val_mse: 3351293952.0000\n",
            "Epoch 190/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2435885945.3072 - mse: 2435885945.3072 - val_loss: 3259077120.0000 - val_mse: 3259077120.0000\n",
            "Epoch 191/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2431033472.4183 - mse: 2431033472.4183 - val_loss: 3384945664.0000 - val_mse: 3384945664.0000\n",
            "Epoch 192/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2444983157.5425 - mse: 2444983157.5425 - val_loss: 3243449088.0000 - val_mse: 3243449088.0000\n",
            "Epoch 193/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2412567386.7712 - mse: 2412567386.7712 - val_loss: 3329780736.0000 - val_mse: 3329780736.0000\n",
            "Epoch 194/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2412227575.8431 - mse: 2412227575.8431 - val_loss: 3313774080.0000 - val_mse: 3313774080.0000\n",
            "Epoch 195/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2399139063.6340 - mse: 2399139063.6340 - val_loss: 3180189440.0000 - val_mse: 3180189440.0000\n",
            "Epoch 196/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2418863764.4967 - mse: 2418863764.4967 - val_loss: 3239572736.0000 - val_mse: 3239572736.0000\n",
            "Epoch 197/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2392427779.7647 - mse: 2392427779.7647 - val_loss: 3298032384.0000 - val_mse: 3298032384.0000\n",
            "Epoch 198/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2390803916.9673 - mse: 2390803916.9673 - val_loss: 3183425024.0000 - val_mse: 3183425024.0000\n",
            "Epoch 199/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2397032819.8693 - mse: 2397032819.8693 - val_loss: 3187840256.0000 - val_mse: 3187840256.0000\n",
            "Epoch 200/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2372867437.8039 - mse: 2372867437.8039 - val_loss: 3230225152.0000 - val_mse: 3230225152.0000\n",
            "Epoch 201/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2371976060.2353 - mse: 2371976060.2353 - val_loss: 3197674240.0000 - val_mse: 3197674240.0000\n",
            "Epoch 202/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2383810800.5229 - mse: 2383810800.5229 - val_loss: 3124242432.0000 - val_mse: 3124242432.0000\n",
            "Epoch 203/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2346916277.1242 - mse: 2346916277.1242 - val_loss: 3248982784.0000 - val_mse: 3248982784.0000\n",
            "Epoch 204/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2359838452.7059 - mse: 2359838452.7059 - val_loss: 3228439040.0000 - val_mse: 3228439040.0000\n",
            "Epoch 205/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2343954507.2941 - mse: 2343954507.2941 - val_loss: 3135692800.0000 - val_mse: 3135692800.0000\n",
            "Epoch 206/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2322180767.1634 - mse: 2322180767.1634 - val_loss: 3146536192.0000 - val_mse: 3146536192.0000\n",
            "Epoch 207/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2338465456.3137 - mse: 2338465456.3137 - val_loss: 3016998400.0000 - val_mse: 3016998400.0000\n",
            "Epoch 208/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2319754139.1895 - mse: 2319754139.1895 - val_loss: 3209305088.0000 - val_mse: 3209305088.0000\n",
            "Epoch 209/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2312071688.7843 - mse: 2312071688.7843 - val_loss: 3176007424.0000 - val_mse: 3176007424.0000\n",
            "Epoch 210/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2328935068.4444 - mse: 2328935068.4444 - val_loss: 3191893760.0000 - val_mse: 3191893760.0000\n",
            "Epoch 211/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2335921804.9673 - mse: 2335921804.9673 - val_loss: 3228689920.0000 - val_mse: 3228689920.0000\n",
            "Epoch 212/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2293881329.3595 - mse: 2293881329.3595 - val_loss: 3210518528.0000 - val_mse: 3210518528.0000\n",
            "Epoch 213/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2277261275.8170 - mse: 2277261275.8170 - val_loss: 3164679680.0000 - val_mse: 3164679680.0000\n",
            "Epoch 214/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2278469099.2941 - mse: 2278469099.2941 - val_loss: 3054966528.0000 - val_mse: 3054966528.0000\n",
            "Epoch 215/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2303447102.3268 - mse: 2303447102.3268 - val_loss: 3137263616.0000 - val_mse: 3137263616.0000\n",
            "Epoch 216/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2276598385.3595 - mse: 2276598385.3595 - val_loss: 3064226048.0000 - val_mse: 3064226048.0000\n",
            "Epoch 217/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2277782224.7320 - mse: 2277782224.7320 - val_loss: 3107157504.0000 - val_mse: 3107157504.0000\n",
            "Epoch 218/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2267204620.9673 - mse: 2267204620.9673 - val_loss: 2972771840.0000 - val_mse: 2972771840.0000\n",
            "Epoch 219/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2257394737.1503 - mse: 2257394737.1503 - val_loss: 3057159424.0000 - val_mse: 3057159424.0000\n",
            "Epoch 220/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2249917616.5229 - mse: 2249917616.5229 - val_loss: 3024798464.0000 - val_mse: 3024798464.0000\n",
            "Epoch 221/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2239368865.4641 - mse: 2239368865.4641 - val_loss: 2998460928.0000 - val_mse: 2998460928.0000\n",
            "Epoch 222/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2232856700.2353 - mse: 2232856700.2353 - val_loss: 3107863808.0000 - val_mse: 3107863808.0000\n",
            "Epoch 223/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2229631372.5490 - mse: 2229631372.5490 - val_loss: 2976959488.0000 - val_mse: 2976959488.0000\n",
            "Epoch 224/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2237334951.3203 - mse: 2237334951.3203 - val_loss: 3092434432.0000 - val_mse: 3092434432.0000\n",
            "Epoch 225/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2217272685.8039 - mse: 2217272685.8039 - val_loss: 3057332480.0000 - val_mse: 3057332480.0000\n",
            "Epoch 226/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2217998210.0915 - mse: 2217998210.0915 - val_loss: 2993625600.0000 - val_mse: 2993625600.0000\n",
            "Epoch 227/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2211160725.9608 - mse: 2211160725.9608 - val_loss: 3044875520.0000 - val_mse: 3044875520.0000\n",
            "Epoch 228/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2207322285.8039 - mse: 2207322285.8039 - val_loss: 2973184000.0000 - val_mse: 2973184000.0000\n",
            "Epoch 229/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2196732679.3203 - mse: 2196732679.3203 - val_loss: 2944359424.0000 - val_mse: 2944359424.0000\n",
            "Epoch 230/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2174872647.3203 - mse: 2174872647.3203 - val_loss: 2945906688.0000 - val_mse: 2945906688.0000\n",
            "Epoch 231/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2159135495.1111 - mse: 2159135495.1111 - val_loss: 2831691520.0000 - val_mse: 2831691520.0000\n",
            "Epoch 232/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2151753954.0915 - mse: 2151753954.0915 - val_loss: 3071544576.0000 - val_mse: 3071544576.0000\n",
            "Epoch 233/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2165227338.0392 - mse: 2165227338.0392 - val_loss: 3070260224.0000 - val_mse: 3070260224.0000\n",
            "Epoch 234/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2152416091.1895 - mse: 2152416091.1895 - val_loss: 2953828096.0000 - val_mse: 2953828096.0000\n",
            "Epoch 235/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2164922200.6797 - mse: 2164922200.6797 - val_loss: 2930450688.0000 - val_mse: 2930450688.0000\n",
            "Epoch 236/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2125336422.2745 - mse: 2125336422.2745 - val_loss: 2932561920.0000 - val_mse: 2932561920.0000\n",
            "Epoch 237/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2127144285.0719 - mse: 2127144285.0719 - val_loss: 3006531328.0000 - val_mse: 3006531328.0000\n",
            "Epoch 238/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2106926012.6536 - mse: 2106926012.6536 - val_loss: 2888380160.0000 - val_mse: 2888380160.0000\n",
            "Epoch 239/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2113640171.7124 - mse: 2113640171.7124 - val_loss: 3078478080.0000 - val_mse: 3078478080.0000\n",
            "Epoch 240/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2119426344.9935 - mse: 2119426344.9935 - val_loss: 2787388160.0000 - val_mse: 2787388160.0000\n",
            "Epoch 241/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2098885937.1503 - mse: 2098885937.1503 - val_loss: 2932383232.0000 - val_mse: 2932383232.0000\n",
            "Epoch 242/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2104064171.2941 - mse: 2104064171.2941 - val_loss: 2726643200.0000 - val_mse: 2726643200.0000\n",
            "Epoch 243/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2093198635.2941 - mse: 2093198635.2941 - val_loss: 2810656512.0000 - val_mse: 2810656512.0000\n",
            "Epoch 244/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2080289472.0000 - mse: 2080289472.0000 - val_loss: 2708135168.0000 - val_mse: 2708135168.0000\n",
            "Epoch 245/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2074916858.3529 - mse: 2074916858.3529 - val_loss: 2713403648.0000 - val_mse: 2713403648.0000\n",
            "Epoch 246/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2064261720.6797 - mse: 2064261720.6797 - val_loss: 2836878080.0000 - val_mse: 2836878080.0000\n",
            "Epoch 247/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2067355805.6993 - mse: 2067355805.6993 - val_loss: 2891563264.0000 - val_mse: 2891563264.0000\n",
            "Epoch 248/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2041387893.3333 - mse: 2041387893.3333 - val_loss: 2816649216.0000 - val_mse: 2816649216.0000\n",
            "Epoch 249/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2037556450.5098 - mse: 2037556450.5098 - val_loss: 2763846912.0000 - val_mse: 2763846912.0000\n",
            "Epoch 250/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2060755263.1634 - mse: 2060755263.1634 - val_loss: 2782580480.0000 - val_mse: 2782580480.0000\n",
            "Epoch 251/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2050912954.7712 - mse: 2050912954.7712 - val_loss: 2724137984.0000 - val_mse: 2724137984.0000\n",
            "Epoch 252/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2044059821.3856 - mse: 2044059821.3856 - val_loss: 2687878912.0000 - val_mse: 2687878912.0000\n",
            "Epoch 253/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 2018358632.7843 - mse: 2018358632.7843 - val_loss: 2547158016.0000 - val_mse: 2547158016.0000\n",
            "Epoch 254/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1988580229.2288 - mse: 1988580229.2288 - val_loss: 2772341504.0000 - val_mse: 2772341504.0000\n",
            "Epoch 255/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1998824795.6078 - mse: 1998824795.6078 - val_loss: 2773021952.0000 - val_mse: 2773021952.0000\n",
            "Epoch 256/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1989628119.2157 - mse: 1989628119.2157 - val_loss: 2658715648.0000 - val_mse: 2658715648.0000\n",
            "Epoch 257/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1989142380.7582 - mse: 1989142380.7582 - val_loss: 2739936512.0000 - val_mse: 2739936512.0000\n",
            "Epoch 258/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1972122977.0458 - mse: 1972122977.0458 - val_loss: 2678736128.0000 - val_mse: 2678736128.0000\n",
            "Epoch 259/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1985136030.5359 - mse: 1985136030.5359 - val_loss: 2701797120.0000 - val_mse: 2701797120.0000\n",
            "Epoch 260/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1972295949.1765 - mse: 1972295949.1765 - val_loss: 2599160832.0000 - val_mse: 2599160832.0000\n",
            "Epoch 261/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1951607019.0850 - mse: 1951607019.0850 - val_loss: 2660735232.0000 - val_mse: 2660735232.0000\n",
            "Epoch 262/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1941404098.9281 - mse: 1941404098.9281 - val_loss: 2519177728.0000 - val_mse: 2519177728.0000\n",
            "Epoch 263/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1934123642.9804 - mse: 1934123642.9804 - val_loss: 2523542528.0000 - val_mse: 2523542528.0000\n",
            "Epoch 264/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1946699616.2092 - mse: 1946699616.2092 - val_loss: 2718468864.0000 - val_mse: 2718468864.0000\n",
            "Epoch 265/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1929992139.9216 - mse: 1929992139.9216 - val_loss: 2906682368.0000 - val_mse: 2906682368.0000\n",
            "Epoch 266/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1902575653.0196 - mse: 1902575653.0196 - val_loss: 2653586432.0000 - val_mse: 2653586432.0000\n",
            "Epoch 267/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1914020897.4641 - mse: 1914020897.4641 - val_loss: 2655034624.0000 - val_mse: 2655034624.0000\n",
            "Epoch 268/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1903951231.3725 - mse: 1903951231.3725 - val_loss: 2617512448.0000 - val_mse: 2617512448.0000\n",
            "Epoch 269/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1882736044.3399 - mse: 1882736044.3399 - val_loss: 2447003648.0000 - val_mse: 2447003648.0000\n",
            "Epoch 270/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1887911410.4052 - mse: 1887911410.4052 - val_loss: 2549689856.0000 - val_mse: 2549689856.0000\n",
            "Epoch 271/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1888262219.9216 - mse: 1888262219.9216 - val_loss: 2437077504.0000 - val_mse: 2437077504.0000\n",
            "Epoch 272/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1865897077.7516 - mse: 1865897077.7516 - val_loss: 2580022016.0000 - val_mse: 2580022016.0000\n",
            "Epoch 273/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1852281402.5621 - mse: 1852281402.5621 - val_loss: 2605514240.0000 - val_mse: 2605514240.0000\n",
            "Epoch 274/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1859932320.2092 - mse: 1859932320.2092 - val_loss: 2474010880.0000 - val_mse: 2474010880.0000\n",
            "Epoch 275/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1858306664.9935 - mse: 1858306664.9935 - val_loss: 2425102336.0000 - val_mse: 2425102336.0000\n",
            "Epoch 276/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1857014950.9020 - mse: 1857014950.9020 - val_loss: 2438496512.0000 - val_mse: 2438496512.0000\n",
            "Epoch 277/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1836653878.1699 - mse: 1836653878.1699 - val_loss: 2599658496.0000 - val_mse: 2599658496.0000\n",
            "Epoch 278/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1821028076.5490 - mse: 1821028076.5490 - val_loss: 2462542336.0000 - val_mse: 2462542336.0000\n",
            "Epoch 279/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1826181426.8235 - mse: 1826181426.8235 - val_loss: 2367871232.0000 - val_mse: 2367871232.0000\n",
            "Epoch 280/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1830193106.1961 - mse: 1830193106.1961 - val_loss: 2476825856.0000 - val_mse: 2476825856.0000\n",
            "Epoch 281/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1810744804.3922 - mse: 1810744804.3922 - val_loss: 2639997952.0000 - val_mse: 2639997952.0000\n",
            "Epoch 282/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1813468582.9020 - mse: 1813468582.9020 - val_loss: 2490645248.0000 - val_mse: 2490645248.0000\n",
            "Epoch 283/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1809607759.2680 - mse: 1809607759.2680 - val_loss: 2544784640.0000 - val_mse: 2544784640.0000\n",
            "Epoch 284/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1786948309.1242 - mse: 1786948309.1242 - val_loss: 2450547200.0000 - val_mse: 2450547200.0000\n",
            "Epoch 285/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1766984424.3660 - mse: 1766984424.3660 - val_loss: 2340121600.0000 - val_mse: 2340121600.0000\n",
            "Epoch 286/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1765070511.0588 - mse: 1765070511.0588 - val_loss: 2408112640.0000 - val_mse: 2408112640.0000\n",
            "Epoch 287/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1765529797.8562 - mse: 1765529797.8562 - val_loss: 2576229632.0000 - val_mse: 2576229632.0000\n",
            "Epoch 288/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1773500464.5229 - mse: 1773500464.5229 - val_loss: 2323089664.0000 - val_mse: 2323089664.0000\n",
            "Epoch 289/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1755225258.6667 - mse: 1755225258.6667 - val_loss: 2201455872.0000 - val_mse: 2201455872.0000\n",
            "Epoch 290/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1738856704.8366 - mse: 1738856704.8366 - val_loss: 2339607040.0000 - val_mse: 2339607040.0000\n",
            "Epoch 291/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1729666662.9020 - mse: 1729666662.9020 - val_loss: 2582123264.0000 - val_mse: 2582123264.0000\n",
            "Epoch 292/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1737744516.1830 - mse: 1737744516.1830 - val_loss: 2668164352.0000 - val_mse: 2668164352.0000\n",
            "Epoch 293/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1718951728.3137 - mse: 1718951728.3137 - val_loss: 2298305280.0000 - val_mse: 2298305280.0000\n",
            "Epoch 294/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1693240181.1242 - mse: 1693240181.1242 - val_loss: 2356288768.0000 - val_mse: 2356288768.0000\n",
            "Epoch 295/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1696950794.4575 - mse: 1696950794.4575 - val_loss: 2336779776.0000 - val_mse: 2336779776.0000\n",
            "Epoch 296/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1695445124.8105 - mse: 1695445124.8105 - val_loss: 2236027392.0000 - val_mse: 2236027392.0000\n",
            "Epoch 297/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1675366069.7516 - mse: 1675366069.7516 - val_loss: 2129752448.0000 - val_mse: 2129752448.0000\n",
            "Epoch 298/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1694136642.0915 - mse: 1694136642.0915 - val_loss: 2306713856.0000 - val_mse: 2306713856.0000\n",
            "Epoch 299/300\n",
            "611/611 [==============================] - 6s 10ms/step - loss: 1680061187.9739 - mse: 1680061187.9739 - val_loss: 2350180608.0000 - val_mse: 2350180608.0000\n",
            "Epoch 300/300\n",
            "611/611 [==============================] - 6s 11ms/step - loss: 1660082064.7320 - mse: 1660082064.7320 - val_loss: 2238317568.0000 - val_mse: 2238317568.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNygyKqmN-cq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20j5LDbfN_Fy"
      },
      "source": [
        "val_mse가 훨씬 적어졌다."
      ]
    }
  ]
}